<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>卷积神经网络模型简述</title>
      <link href="/2018/12/23/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AE%80%E8%BF%B0/"/>
      <url>/2018/12/23/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%AE%80%E8%BF%B0/</url>
      <content type="html"><![CDATA[<p>  上篇博客从信号处理的角度解析了卷积计算和卷积神经网络中的卷积卷积操作。本文主要梳理一遍经典的卷积架构，如：ResNet，Inception架构，这些架构在CV任务上的表现十分出色，同时也给众多深度学习提供了新的思路，例如后来的DenseNet、ResNeXt等。以后有时间将扩展，偏功能的卷积架构有，在细粒度特征上可以采用SPPNet以及Few-shot learning 上的SiameseNet，图像分割中的FCN。本文将以LeNet简单介绍卷积基础架构开始，以讲述Blocks演变的形式简单讲解不同网络的特点。</p><a id="more"></a><figure><img src="/images/CNN%20modules_acc_vs_net_vs_ops.png" alt="卷积模型发展"><figcaption>卷积模型发展</figcaption></figure><h2 id="卷机神经网络基础架构">卷机神经网络基础架构</h2><p>  典型的神经网络由一个输入层，多个隐藏层和一个输出层组成，在卷积神经网络中称为全连接。对于每一层的输出：<span class="math inline">\(y_i=f(W_{i}x +b)，其中f(x)为激活函数\)</span>；其经典结构如下图所示：</p><figure><img src="/images/神经网络经典结构.png" alt="神经网络结构"><figcaption>神经网络结构</figcaption></figure><p>  卷积神经网络的基础结构如下图所示：</p><figure><img src="/images/基础卷积架构.png" alt="完整的卷积结构"><figcaption>完整的卷积结构</figcaption></figure><p>  卷积神经网络采用的权值共享，相对与全连接操作，通常减少了数量级的参数；此外，卷积神经网络的局部操作，在处理具有局部相关性的任务时，与全连接相比具有明显的优势。</p><h4 id="todo">TODO:</h4><p>卷积神经网络的构成成分：</p><ul><li>[x] 卷积层</li><li>[x] 池化层</li><li>[x] 全连接层（FCN和输出层前是Global_pooling的架构没有）</li><li>激活函数</li><li>Batch Nomalization(BN层)</li><li>局部响应归一化（LRN）</li><li>Dropout层</li></ul><h2 id="lenet5">LeNet5</h2><p>  LeNet5架构是一个开创性的工作。图像特征是全局和局部的统一，LeNet5利用一组相同的卷积核在特征图的一个通道上对全局特征进行滤波处理，同时融合局部特征，利用下采样压缩局部的相似特征。当时没有GPU来帮助训练，甚至CPU速度都非常慢。因此，对比使用每个像素作为一个单独的输入的多层神经网络，LeNet5能够节省参数和计算是一个关键的优势。LeNet5论文中提到，全连接不应该被放在第一层，因为图像中有着高度的空间相关性，并利用图像各个像素作为单独的输入特征不会利用这些相关性。因此有了CNN的三个特性了：<strong>1.局部感知、2.平移不变性（下采样）、3.权值共享</strong>。</p><figure><img src="/images/lenet-5.png" alt="LeNet-5"><figcaption>LeNet-5</figcaption></figure><h2 id="alexnet">AlexNet</h2><p>AlexNet特点：</p><ul><li>由五层卷积和三层全连接组成，输入图像为三通道 224x224 大小，网络规模远大于 LeNet-5</li><li>使用了 ReLU 激活函数，提高了训练速度</li><li>使用了 Dropout，可以作为正则项防止过拟合，提升模型鲁棒性</li><li>加入了局部响应归一化（LRN）提高了精度</li><li>引入最大池化</li><li>在训练时使用了分组卷积操作（参见《卷积神经网络（上）》）</li><li>一些很好的训练技巧，包括数据增广、学习率策略、weight decay 等</li></ul><p>AlexNet架构：</p><figure><img src="/images/alexnet.jpg" alt="AlexNet"><figcaption>AlexNet</figcaption></figure><figure><img src="/images/AlexNet-Ag.png" alt="Ng-AlexNet"><figcaption>Ng-AlexNet</figcaption></figure><h2 id="vgg">VGG</h2><p>  VGG是一种更简单的架构模型，因为它没有使用太多的超参数。它总是使用3 x 3滤波器，在卷积层中步长为1，并使用SAME填充在2 x 2池中，步长为2。</p><ul><li><p>VGG使用3*3卷积核级联提高感受野，一改LeNet-5和AlexNet的<code>卷积-池化</code>结构。</p></li><li><p>VGG模型更深，参数更少，后续的模型基本都遵循了小卷积核级联的设计风格。</p><figure><img src="/images/VGG.jpg" alt="VGG"><figcaption>VGG</figcaption></figure></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Keras API</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">block2_conv</span><span class="params">(x)</span>:</span></span><br><span class="line">    x = Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>, name=<span class="string">'block2_conv1'</span>)(x)</span><br><span class="line">    x = Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">'relu'</span>, padding=<span class="string">'same'</span>, name=<span class="string">'block2_conv2'</span>)(x)</span><br><span class="line">    x = MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">2</span>, <span class="number">2</span>), name=<span class="string">'block2_pool'</span>)(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="googlenet">GoogLeNet</h2><p>  2014年ILSVRC的获胜者提出GoogLeNet架构也称为InceptionV1模型。它在具有不同感受野大小的并行路径中更深入，并且降低了Top5错误率到6.67％。该架构由22层深层组成。它将参数数量从6000万（AlexNet）减少到500万。<strong>GoogLeNet在使用了中间输出做了多任务学习，防止网络过深造成的梯度消失的情况；每层使用多个卷积核</strong>。</p><figure><img src="/images/GoogLeNet-incaption.png" alt="GoogLeNet-inception"><figcaption>GoogLeNet-inception</figcaption></figure><h2 id="inception-v2">Inception V2</h2><p>  Iception V2 主要提出了Batch Nomalization(BN)，BN层对mini-batch内部数据进行标准化，再给标准化数据乘以权重和加bias，保证了模型可以学习回原来的分布。用了BN层后减少或者取消 <strong>LRN</strong>。</p><ul><li>[ ] 后续有时间再写一个博客专门写深度学习的正则化， 可以关注<a href="https://mp.weixin.qq.com/s/uQUUI9G10SOUQwvYqG78Mg" target="_blank" rel="noopener">深度学习中的Nomalization中的分析</a>。</li></ul><h2 id="inception-v3">Inception V3</h2><p>  Inception V3将一个较大的二维卷积拆成两个较小的一维卷积，比如将7x7卷积拆成1x7卷积和7x1卷积，或者将3x3卷积拆成1x3卷积和3x1卷积，另外也使用了将5x5 用两个 3x3 卷积替换，7x7 用三个 3x3 卷积替换，如下图所示。一方面节约了大量参数，加速运算并减轻了过拟合，同时增加了一层非线性扩展模型表达能力。论文中指出，这种非对称的卷积结构拆分，其结果比对称地拆为几个相同的小卷积核效果更明显，可以处理更多、更丰富的空间特征，增加特征多样性。示意图如下：</p><figure><img src="/images/1x3卷积核代替3x3卷积.jpg" alt="1x3卷积核代替3x3卷积核"><figcaption>1x3卷积核代替3x3卷积核</figcaption></figure><figure><img src="/images/使用一维卷积核代替二维卷积核.jpg" alt="使用一维卷积核代替二维卷积核"><figcaption>使用一维卷积核代替二维卷积核</figcaption></figure><h2 id="resnet">ResNet</h2><p>  ILSRVC 2015的获胜者，被何凯明大神称为残差网络（ResNet）。该架构引入了一个名为“skip connections”的概念。ResNet采用Shortcut单元实现信息的跨层流通。与Inception 模块的Concat操作不同，Residual 模块使用 Add 操作完成信息融合。</p><figure><img src="/images/shortcut.jpg" alt="shotcut"><figcaption>shotcut</figcaption></figure><p>  通过引入直连，原来需要学习完全的重构映射，从头创建输出，并不容易，而引入直连之后，只需要学习输出和原来输入的差值即可，绝对量变相对量，容易很多，所以叫残差网络。并且，通过引入残差，identity 恒等映射，相当于一个梯度高速通道，可以容易地训练避免梯度消失的问题，所以可以得到很深的网络，网络层数由 GoogLeNet 的 22 层到了ResNet的 152 层。然而，恒等函数与<span class="math inline">\(H_{\ ell}\)</span>的输出是通过求和组合，这可能阻碍网络中的信息流。</p><p>  <a href="https://github.com/keras-team/keras-applications/tree/master/keras_applications" target="_blank" rel="noopener">keras_applications实现的Identity Block:</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">identity_block</span><span class="params">(input_tensor, kernel_size, filters, stage, block)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    The identity block is the block that has no conv layer at shortcut.</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        input_tensor: input tensor</span></span><br><span class="line"><span class="string">        kernel_size: default 3, the kernel size of</span></span><br><span class="line"><span class="string">            middle conv layer at main path</span></span><br><span class="line"><span class="string">        filters: list of integers, the filters of 3 conv layer at main path</span></span><br><span class="line"><span class="string">        stage: integer, current stage label, used for generating layer names</span></span><br><span class="line"><span class="string">        block: 'a','b'..., current block label, used for generating layer names</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        Output tensor for the block.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    filters1, filters2, filters3 = filters</span><br><span class="line">    <span class="keyword">if</span> backend.image_data_format() == <span class="string">'channels_last'</span>:</span><br><span class="line">        bn_axis = <span class="number">3</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bn_axis = <span class="number">1</span></span><br><span class="line">    conv_name_base = <span class="string">'res'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line">    bn_name_base = <span class="string">'bn'</span> + str(stage) + block + <span class="string">'_branch'</span></span><br><span class="line"></span><br><span class="line">    x = layers.Conv2D(filters1, (<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                      kernel_initializer=<span class="string">'he_normal'</span>,</span><br><span class="line">                      name=conv_name_base + <span class="string">'2a'</span>)(input_tensor)</span><br><span class="line">    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + <span class="string">'2a'</span>)(x)</span><br><span class="line">    x = layers.Activation(<span class="string">'relu'</span>)(x)</span><br><span class="line"></span><br><span class="line">    x = layers.Conv2D(filters2, kernel_size,</span><br><span class="line">                      padding=<span class="string">'same'</span>,</span><br><span class="line">                      kernel_initializer=<span class="string">'he_normal'</span>,</span><br><span class="line">                      name=conv_name_base + <span class="string">'2b'</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + <span class="string">'2b'</span>)(x)</span><br><span class="line">    x = layers.Activation(<span class="string">'relu'</span>)(x)</span><br><span class="line"></span><br><span class="line">    x = layers.Conv2D(filters3, (<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                      kernel_initializer=<span class="string">'he_normal'</span>,</span><br><span class="line">                      name=conv_name_base + <span class="string">'2c'</span>)(x)</span><br><span class="line">    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + <span class="string">'2c'</span>)(x)</span><br><span class="line"></span><br><span class="line">    x = layers.add([x, input_tensor])</span><br><span class="line">    x = layers.Activation(<span class="string">'relu'</span>)(x)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>  ResNet-34 的网络结构如下所示：</p><figure><img src="/images/ResNet-34.jpg" alt="ResNet-34"><figcaption>ResNet-34</figcaption></figure><p>不同的ResNet结构对比：</p><figure><img src="/images/ResNet_mode.jpg" alt="resnet结构"><figcaption>resnet结构</figcaption></figure><h2 id="densenet">DenseNet</h2><p>  说到DenseNet全文就俩公式，当时我还觉得我咋写不出来这样的论文~~。</p><p>先预览下<a href="https://arxiv.org/abs/1608.06993" target="_blank" rel="noopener">DenseNet论文</a>里的DenseBlocks:</p><figure><img src="/images/DenseNetBlock.png" alt="DenseBlock"><figcaption>DenseBlock</figcaption></figure><p>  <strong>ResNet：</strong>传统的前馈卷积神经网络将第+1层的输入，可表示为：<span class="math inline">\(x_{\ell} = H_{\ell}(x_{\ell-1})\)</span>。ResNet添加了一个跳连接，即使用恒等函数跳过非线性变换： <span class="math display">\[x_{\ell} = H_{\ell}(x_{\ell-1}) + x_{\ell-1}\]</span></p><p><strong>密集连接：</strong>为了进一步改善层之间的信息流，我们提出了不同的连接模式：我们提出从任何层到所有后续层的直接连接。因此，第<span class="math inline">\(x_{0},…,x_{\ell-1}\)</span>作为输入: <span class="math display">\[x_{\ell} = H_{\ell}([x_{0},x_{1},...,x_{\ell-1}])\]</span>   如果说Iception ResNet V2是Inception 思想融合了ResNet，那么我认为 DenseNet就是 Residual 思想（信息跨层流通）结合了Inception 理念。</p><figure><img src="/images/densenet.png" alt="densenet"><figcaption>densenet</figcaption></figure><p>DenseNet的几个重要参数：</p><p>  <strong>增长率：</strong>如果每个<span class="math inline">\(H_{\ell}\)</span>层输出K个特征图，那么第<span class="math inline">\(\ell\)</span>层输出<span class="math inline">\(K_{0}+K(\ell-1)\)</span>个特征图，其中<span class="math inline">\(K_{0}\)</span>是输入层的通道数。</p><p>  <strong>瓶颈层：</strong>即<span class="math inline">\(1\times1\)</span>卷积层。每一层输出<span class="math inline">\(K_{0}+K(\ell-1)\)</span>个，理论上将每个输出为个Feature Maps，理论上将每个Dense Block输出为K_{0}+_{1}^{}K(i-1)$个Fature Maps，。<span class="math inline">\(1\times1\)</span>卷积层的作用是将一个Dense Block的特征图压缩到<span class="math inline">\(K_{0}+K\ell\)</span>个。</p><p>  <strong>压缩：</strong>为了进一步提高模型的紧凑性，我们可以在过渡层减少特征图的数量。。作者选择压缩率（theta）为0.5。包含Bottleneck Layer的叫DenseNet-B，包含压缩层的叫DenseNet-C，两者都包含的叫DenseNet-BC</p><p><a href="">keras_applications实现的密集连接模块</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dense_block</span><span class="params">(x, blocks, name)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    A dense block.</span></span><br><span class="line"><span class="string">    # Arguments</span></span><br><span class="line"><span class="string">        x: input tensor.</span></span><br><span class="line"><span class="string">        blocks: integer, the number of building blocks.</span></span><br><span class="line"><span class="string">        name: string, block label.</span></span><br><span class="line"><span class="string">    # Returns</span></span><br><span class="line"><span class="string">        output tensor for the block.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(blocks):</span><br><span class="line">        x = conv_block(x, <span class="number">32</span>, name=name + <span class="string">'_block'</span> + str(i + <span class="number">1</span>))</span><br><span class="line">        <span class="comment">#每个conv_blocks的输出是[x,conv_block(x, 32, name=name + '_block' + str(i + 1))]</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h2 id="senet">SENet</h2><p>  SENet(Squeeze-and-Excitation Networks)是基于特征通道之间的关系提出的，下图是SENet的Block单元，图中的Ftr是传统的卷积结构，X和U是Ftr的输入和输出，这些都是以往结构中已存在的。SENet增加的部分是U后的结构：对U先做一个Global Average Pooling（称为Squeeze过程），输出是一个1x1xC的数据，再经过两级全连接（称为Excitation过程），最后用sigmoid把输出限制到[0，1]的范围，把这个值作为scale再乘到U的C个通道上，作为下一级的输入数据。这种结构的原理是想通过控制scale的大小，把重要的特征增强，不重要的特征减弱，从而让提取的特征指向性更强。</p><figure><img src="/images/SENet.jpg" alt="SENet"><figcaption>SENet</figcaption></figure><p>其实<strong>SENet就是通道级attention机制</strong>。</p><p><a href="https://github.com/taki0112/SENet-Tensorflow" target="_blank" rel="noopener">由Tensorflow 实现的SE模块：</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Squeeze_excitation_layer</span><span class="params">(self, input_x, out_dim, ratio, layer_name)</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(layer_name) :</span><br><span class="line">        squeeze = Global_Average_Pooling(input_x)</span><br><span class="line">        excitation = Fully_connected(squeeze, units=out_dim / ratio, layer_name=layer_name+<span class="string">'_fully_connected1'</span>)</span><br><span class="line">        excitation = Relu(excitation)</span><br><span class="line">        excitation = Fully_connected(excitation, units=out_dim, layer_name=layer_name+<span class="string">'_fully_connected2'</span>)</span><br><span class="line">        excitation = Sigmoid(excitation)</span><br><span class="line">        excitation = tf.reshape(excitation, [<span class="number">-1</span>,<span class="number">1</span>,<span class="number">1</span>,out_dim])</span><br><span class="line">        scale = input_x * excitation</span><br><span class="line">        <span class="keyword">return</span> scale</span><br></pre></td></tr></table></figure><h2 id="总结">总结：</h2><p>卷积神经网络设计：</p><ol type="1"><li><p>从防止梯度消失出发</p></li><li><p>从信息流通出发</p></li><li><p>从多尺度特征图融合出发</p></li><li><p>从通道级或者像素级特征选择出发</p></li></ol><h2 id="reference">Reference</h2><ol type="1"><li><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="noopener">LeNet</a></li><li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">AlexNet</a></li><li><a href="https://arxiv.org/abs/1312.4400" target="_blank" rel="noopener">Network-in-network</a></li><li><a href="http://arxiv.org/abs/1409.1556" target="_blank" rel="noopener">VGG</a></li><li><a href="https://arxiv.org/abs/1409.4842" target="_blank" rel="noopener">GoogleNet</a></li><li><a href="http://arxiv.org/abs/1512.00567" target="_blank" rel="noopener">Inception V3</a></li><li><a href="http://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Batch-normalized</a></li><li><a href="https://arxiv.org/pdf/1512.03385v1.pdf" target="_blank" rel="noopener">ResNet</a></li><li>Hu J, Shen L, Sun G. Squeeze-and-Excitation Networks[J]. 2017.</li><li>https://chenzomi12.github.io/2016/12/13/CNN-Architectures/</li></ol>]]></content>
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 卷积神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ResNet </tag>
            
            <tag> Inception </tag>
            
            <tag> SENet </tag>
            
            <tag> ShuffleNet </tag>
            
            <tag> MobileNet </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>卷积神经网络</title>
      <link href="/2018/12/23/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2018/12/23/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<p>  很多人在接触卷积神经网络之前就接触过卷积运算，比如信号与系统的连续信号卷积和离散信号卷积。本文将我的理解出发对比卷积神经网络的卷积和我们信号卷积的区别与联系。介绍卷积神经网络中的卷积操作，以及不同的卷积策略。为后续深入高效小网络及模型压缩相关概念和原理做准备。</p><a id="more"></a><h2 id="信号卷积">信号卷积</h2><p>  卷积表征函数<em>f</em>与经过翻转和平移的<em>g</em>的乘积函数所围成的曲边梯形的面积。信号与系统中，采样信号经过系统响应得到系统输出。一维卷积的数学表达： <span class="math display">\[离散卷积：z[n]=(x * y)[n] = \sum_{m = -\infty}^{+\infty}x[m]\cdot y[n - m]\\连续卷积： y(x)=(f * h)(t) = \int_{-\infty}^{+\infty}f(\tau)\cdot h(t - \tau)\mathop{}\!\mathrm{d}\tau\]</span>   我们采集到的信号通常是离散的，因此，后续讲解的就是离散卷积。看下维基百科的卷积可视化。 <img src="/images/Convolution_of_box_signal_with_itself2.gif" alt="离散卷积1"> <img src="/images/Convolution_of_spiky_function_with_box2.gif" alt="离散卷积2"></p><figure><img src="/images/automatic_investment_plan.gif" alt="离散卷积3"><figcaption>离散卷积3</figcaption></figure><p>  一维离散卷积比较好理解，每个输出元素都是卷积核（系统响应）和信号的局部乘积的和。卷积操作是一种滤波操作，信号与系统的高通滤波，低通滤波等，因此，通过卷积操作可以获得某个方面属性的增强。一维离散卷积通常是在时域卷积，图像，激光雷达回波等属于空间属性。</p><h2 id="cnn的卷积">CNN的卷积</h2><h3 id="卷积计算">卷积计算</h3><p>  以图像为例。图像卷积即二维离散卷积，图像的矩阵表示为<span class="math inline">\(h*w\)</span>，元素数值大小为无符号整型通常在[0,255]之间。二维离散卷积的公式定义： <span class="math display">\[S[i, j] = (F ∗ K)(i, j) = \sum_m\sum_n F(m, n)K(i − m, j − n)\]</span> 卷积是可交换的(commutative)，该公式可转变为： <span class="math display">\[S[i, j] = (F ∗ K)(i, j) = \sum_m\sum_n F(i-m, i-n)K( m, n),K即我们常说的卷积核\]</span></p><p>图像卷积示例：</p><figure><img src="/images/滑动卷积.gif" alt="二维卷积示例1"><figcaption>二维卷积示例1</figcaption></figure><p>  参数：输入Shape：<span class="math inline">\((7\times7\times3)\)</span> 卷积核Shape:<span class="math inline">\(3\times3\times3\times2\)</span> <span class="math inline">\(zero-padding=1 stride=2\)</span></p><p>输出Shape计算： <span class="math display">\[\begin{align}W_2 &amp;= (W_1 - F + 2P)/S + 1\qquad(式2)\\H_2 &amp;= (H_1 - F + 2P)/S + 1\qquad(式3)\end{align}\]</span></p><h3 id="卷积层">卷积层</h3><p>  卷积层的作用是提取一个局部区域的特征，不同的卷积核相当于不同的特征提取器。上一节中描述的卷积层的神经元和全连接网络一样都是一维结构。既然卷积网络主要应用在图像处理上，而图像为两维结构，因此为了更充分地利用图像的局部信息，通常将神经元组织为三维结构的神经层，其大小为高度H×宽度W×深度C，有C个H ×W 大小的特征映射构成。   特征映射（feature map）为一幅图像（或其它特征映射）在经过卷积提取到的特征，每个特征映射可以作为一类抽取的图像特征。为了卷积网络的表示能力，可以在每一层使用多个不同的特征映射，以更好地表示图像的特征。</p><p><strong>卷积层的关键参数</strong>：</p><ul><li><strong>卷积核大小（Kernel Size）</strong>：定义了卷积操作的感受野。在二维卷积中，通常设置为3，即卷积核大小为3×3。</li><li><strong>步幅（Stride）</strong>：定义了卷积核遍历图像时的步幅大小。其默认值通常设置为1，也可将步幅设置为2后对图像进行下采样，这种方式与最大池化类似。</li><li><strong>边界扩充（Padding）</strong>：定义了网络层处理样本边界的方式。当卷积核大于1且不进行边界扩充，输出尺寸将相应缩小；当卷积核以标准方式进行边界扩充，则输出数据的空间尺寸将与输入相等。</li><li><strong>输入与输出通道（Channels）</strong>：构建卷积层时需定义输入通道I，并由此确定输出通道O。这样，可算出每个网络层的参数量为I×O×K，其中K为卷积核的参数个数。例，某个网络层有64个大小为3×3的卷积核，则对应K值为 3×3 =9。</li></ul><p><strong>卷积层特性</strong>：</p><ul><li><p><strong>局部连接</strong>：卷积计算的通俗理解就是卷积核在图像上做滑动卷积，每次滑动输出一个值，局部乘积求和。局部计算如：</p><figure><img src="/images/hudongjuanji.gif" alt="局部求和"><figcaption>局部求和</figcaption></figure></li><li><p><strong>权值共享</strong>：整张图像可以共用一个卷积核，对比全连接操作卷积不需要同时和每个像素点相乘求和(内积)。</p></li></ul><h3 id="池化pooling">池化（pooling）</h3><p>  池化也叫子采样（subsampling layer），其作用是进行特征选择，降低特征数量，并从而减少参数数量。</p><p>  标准的卷积操作虽然可以显著减少网络中连接的数量，但特征映射组中的神经元个数并没有显著减少。如果后面接一个分类器，分类器的输入维数依然很高，很容易出现过拟合。为了解决这个问题，可以在卷积操作之后加上一个池化操作，从而降低特征维数，避免过拟合。（也可通过增加滑动卷积的步长Stride来达到降维效果）</p><p>  池化操作虽然说有降维功能，同时也是存在信息损失的。</p><figure><img src="/images/池化.png" alt="池化"><figcaption>池化</figcaption></figure><h4 id="常见的池化方式">常见的池化方式</h4><ul><li>最大池化（max-pooling）</li></ul><p>  一般是在池化核对应区域内选取最大值来表征该区域。</p><ul><li>平均池化（mean-pooling）</li></ul><p>  一般是取池化核对应区域内所有元素的均值来表征该区域。</p><ul><li>全局池化（global pooling）</li></ul><p>  一般是对整个特征图进行最大池化或者平均池化。</p><ul><li>重叠池化（overlapping-pooling）</li></ul><p>  相邻池化窗口之间会有重叠区域，此时kernel size&gt;stride</p><h3 id="卷积神经网络中的特殊卷积操作">卷积神经网络中的特殊卷积操作</h3><h4 id="times1卷积核"><span class="math inline">\(1\times1\)</span>卷积核</h4><p>  自从GoogLenet接手发扬光大以后，<span class="math inline">\(1\times1\)</span>卷积广泛出现在新的卷积架构中如xception和小卷积网络中。<span class="math inline">\(1\times1\)</span> 卷积核在单通道上就是给每个像素点同等乘以一个系数，多通道上其实现了通道间的信息流通。从全连接的角度解释即C通道特征图，和C个<span class="math inline">\(1\times1\)</span>卷积核卷积输出1个新的特征图。同理，和K<em>C个1x1的卷积核卷积输出K个特征图。注：全连接运算是元素级的，<span class="math inline">\(1\times1\)</span>卷积是通道级的，对于H</em>W * C的特征图全连接需要K * H * W * C，而1<em>1卷积仅需要K</em>C个参数。图片来自知乎。 <img src="/images/全连接.jpg" alt="全连接"></p><h5 id="times1卷积的作用"><span class="math inline">\(1\times1\)</span>卷积的作用</h5><ul><li>跨通道信息交互（channal 的变换）</li><li>升维（用最少的参数拓宽网络channal）</li><li>降维（减少参数）</li></ul><h4 id="深度可分离卷积depthwise-separable-convolution">深度可分离卷积（depthwise separable convolution）</h4><p>  深度可分离卷积在执行空间卷积，同时保持通道分离，然后进行深度卷积。 可分离卷积与标准的卷积相比，其在通道上先做了卷积然后在再用<span class="math inline">\(1\times1\)</span>卷积进行通道融合。示意图：</p><figure><img src="/images/可分离卷积.jpg" alt="可分离卷积"><figcaption>可分离卷积</figcaption></figure><p>对比标准卷积过程：</p><figure><img src="/images/普通卷积.jpg" alt="标准卷积"><figcaption>标准卷积</figcaption></figure><p>  假设我们在16个输入通道和32个输出通道上有一个3x3卷积层。详细情况是，16个3x3内核遍历16个通道中的每一个，产生512（16x32）个特征映射。接下来，我们通过添加它们来合并每个输入通道中的1个特征图。由于我们可以做32次，我们得到了我们想要的32个输出通道。</p><p>  针对这个例子应用深度可分离卷积，用1个3×3大小的卷积核遍历16通道的数据，得到了16个特征图谱。在融合操作之前，接着用32个1×1大小的卷积核遍历这16个特征图谱，进行相加融合。这个过程使用了16×3×3+16×32×1×1=656个参数，远少于上面的16×32×3×3=4608个参数。</p><p>  这个例子就是深度可分离卷积的具体操作，其中上面的深度乘数（depth multiplier）设为1，这也是目前这类网络层的通用参数。这么做是为了对空间信息和深度信息进行去耦。从Xception模型的效果可以看出，这种方法是比较有效的。由于能够有效利用参数，因此深度可分离卷积也可以用于移动设备中。</p><h4 id="空洞卷积dilated-convolution">空洞卷积（dilated convolution）</h4><p>  dilated convolution是针对图像语义分割问题中下采样会降低图像分辨率、丢失信息而提出的一种卷积思路。</p><p>  空洞卷积的特点是在扩大感受野的同时不增加计算成本。示意图：</p><figure><img src="/images/空洞卷积静态图.jpg" alt="空洞卷积静态图"><figcaption>空洞卷积静态图</figcaption></figure><p>  上图b可以理解为卷积核大小依然是3×3，但是每个卷积点之间有1个空洞，也就是在绿色7×7区域里面，只有9个红色点位置作了卷积处理，其余点权重为0。这样即使卷积核大小不变，但它看到的区域变得更大了 。</p><p>     <strong>空洞卷积的动机：加pooling层，损失信息，降低精度；不加pooling层，感受野变小，模型学习不到全局信息</strong></p><h4 id="组卷积group-convolution">组卷积（Group convolution）</h4><p>  分组卷积（Group convolution） ，最早在AlexNet中出现，由于当时的硬件资源有限，训练AlexNet时卷积操作不能全部放在同一个GPU处理，因此作者把feature maps分给多个GPU分别进行处理，最后把多个GPU的结果进行融合（concatenate）。</p><p>下图分别是一个正常的、没有分组的卷积层结构和分组卷积结构的示意图：</p><figure><img src="/images/gc0.jpg" alt="组卷积"><figcaption>组卷积</figcaption></figure><figure><img src="/images/gc1.jpg" alt="标准卷积_分组"><figcaption>标准卷积_分组</figcaption></figure><p>  组卷积通过将卷积运算的输入限制在每个组内，模型的计算量取得了显著的下降。然而这样做也带来了明显的问题：在多层逐点卷积堆叠时，模型的信息流被分割在各个组内，组与组之间没有信息交换。这将可能影响到模型的表示能力和识别精度。 目前旷世科技提出的ShuffleNet引入通道重排来处理组和组之间的信息流通。</p><p>分组卷积操作实例：</p><p>  从一个具体的例子来看，Group conv本身就极大地减少了参数。比如当输入通道为256，输出通道也为256，kernel size为3×3，不做Group conv参数为256×3×3×256。实施分组卷积时，若group为8，每个group的input channel和output channel均为32，参数为8×32×3×3×32，是原来的八分之一。而Group conv最后每一组输出的feature maps以concatenate的方式组合。 Alex认为group conv的方式能够增加 filter之间的对角相关性，而且能够减少训练参数，不容易过拟合，这类似于正则的效果。</p><h4 id="转置卷积">转置卷积</h4><p>  反卷积是一种上采样操作，在图像分割和卷积自编码中应用较多。示意图：</p><figure><img src="/images/反卷积.gif" alt="转置卷积"><figcaption>转置卷积</figcaption></figure><h3 id="小结">小结</h3><p>  本文简单的介绍了信号卷积的算法原理，引入二维离散卷积引导对卷积神经网络的卷积的理解。卷积是一种滤波操作，在卷积神经网络中有许多卷积变形结构，这些结构从维度控制，信息流通，模型参数大小控制，感受野等角度进行设计。在当前state of art卷积架构中多是融入了部分或者全部上述变形卷积。在设计新的模型时，可从设计目标出发采用上述结构优化，裁剪模型。</p><h2 id="参考">参考</h2><blockquote><ol type="1"><li><p>邱锡鹏 ,《神经网络与深度学习》https://nndl.github.io/&gt;</p></li><li><p>https://zhuanlan.zhihu.com/p/28749411</p></li><li><p>https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d</p></li><li><p>https://www.zhihu.com/question/54149221</p></li><li><p>https://www.cnblogs.com/ranjiewen/articles/8699268.html</p></li><li><p>https://blog.csdn.net/A_a_ron/article/details/79181108</p></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 卷积神经网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 信号卷积 </tag>
            
            <tag> 组卷积 </tag>
            
            <tag> 空洞卷积 </tag>
            
            <tag> 可分离卷积 </tag>
            
            <tag> 1x1卷积 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Tensorflow Object Detection API Win10和Ubuntu双系统教程</title>
      <link href="/2018/12/23/Tensorflow%20Object%20Detection%20API%20Win10%E5%92%8CUbuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F%E6%95%99%E7%A8%8B/"/>
      <url>/2018/12/23/Tensorflow%20Object%20Detection%20API%20Win10%E5%92%8CUbuntu%E5%8F%8C%E7%B3%BB%E7%BB%9F%E6%95%99%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p>本实验的Faster RCNN 源代码实现来自<a href="https://github.com/tensorflow/models/tree/master/research/object_detection" target="_blank" rel="noopener">tensorflow/models 的 object_detection API</a> ；在COCO2014数据集上完成训练和测试，本教程由我、胡保林大神以及韩博士在win10和Ubuntu16.04上完成并测试通过。</p><a id="more"></a><h3 id="环境和依赖准备">1. 环境和依赖准备</h3><ul><li><p>Tensorflow Object Detection API 根据官方安装指示安装<a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" target="_blank" rel="noopener">下载安装</a>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">最后的测试代码： python object_detection/builders/model_builder_test.py</span><br><span class="line">如果返回下图结果，表示上述API安装成功、</span><br><span class="line">如果安装失败，看代码报错debug.</span><br><span class="line">注意：将 object_detection 和 slim 配置到环境变量中，否则会出现 没有这俩个模块的报错</span><br><span class="line">win10:</span><br><span class="line">可以在上述俩个文件夹下运行： python setup.py install</span><br></pre></td></tr></table></figure><figure><img src="/images/env_test.png" alt="完整环境配置完成测试结果"><figcaption>完整环境配置完成测试结果</figcaption></figure></li><li><p>下载 <a href="http://cocodataset.org/#download" target="_blank" rel="noopener">COCO2014数据集</a>. 保持下列数据存储:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">COCO/DIR/</span><br><span class="line">  annotations/</span><br><span class="line">    instances_train2014.json</span><br><span class="line">    instances_val2014.json</span><br><span class="line">  train2014/</span><br><span class="line">    COCO_train2014_*.jpg</span><br><span class="line">  val2014/</span><br><span class="line">    COCO_val2014_*.jpg</span><br></pre></td></tr></table></figure></li></ul><h3 id="object-detection-api部分代码用法">2. Object Detection API部分代码用法</h3><h5 id="创建coco或者voc格式的tfrecord文件">1. 创建COCO或者VOC格式的TFRecord文件</h5><p>  object detection/dataset_tools中包含创建TFRecord的python程序。以创建COCO2014为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">python object detection/dataset_tools/create_coco_tf_record.py --logtostderr \</span><br><span class="line">  --train_image_dir=<span class="string">"E:\TEMP_PROJECTS\\COCO\\train2014\\"</span> \</span><br><span class="line">      --val_image_dir=<span class="string">"E:\TEMP_PROJECTS\\COCO\\val2014\\"</span> \</span><br><span class="line">      -- train_annotations_file=                  <span class="string">"E:\TEMP_PROJECTS\COCO\\annotations/instances_train2014.json"</span>\</span><br><span class="line">      --val_annotations_file=<span class="string">"E:\TEMP_PROJECTS\COCO\\annotations/instances_val2014.json"</span> \</span><br><span class="line">      --output_dir=<span class="string">"../data/coco"</span></span><br><span class="line">    PS:如果不转换测试数据，请在create_coco_tf_record.py中检测<span class="keyword">assert</span>函数将test_file相关代码注释掉</span><br></pre></td></tr></table></figure><figure><img src="/images/create_tfrcord.png" alt="create_tfrcord"><figcaption>create_tfrcord</figcaption></figure><h4 id="训练faster-rcnn-nasnet">2.训练Faster RCNN Nasnet</h4><ul><li>下载预训练模型和修改config文件</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 类别，迭代数，预训练模型路径，tfrecord的路径。（注意：如果只有11G显存，请把config中图像尺寸改成600*600以下）</span><br><span class="line">2. 针对自己数据集修改 类别个数--num_classes</span><br><span class="line">3. samples/configs/faster_rcnn_nas_coco.config文件里面PATH_TO_BE_CONFIGURED 共有5处应替换成对应文件：比如训练集路径，label_map路径，模型权重路径等，详见config文件</span><br><span class="line">4. fine_tune_checkpoint：设置预训练模型权重路径。</span><br><span class="line">5. num_steps 根据实际情况修改</span><br></pre></td></tr></table></figure><ul><li><p>输入训练命令（根目录：research文件夹）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/legacy/train.py  --logtostderr \</span><br><span class="line">        --train_dir=object_detection/data/coco/ \</span><br><span class="line">        --pipeline_config_path=object_detection/samples/configs/faster_rcnn_nas_coco.config</span><br><span class="line">        <span class="comment">#train_dir---训练数据路径</span></span><br><span class="line">        <span class="comment">#pipeline_config_path---config 路径</span></span><br></pre></td></tr></table></figure><figure><img src="/images/train_process.png" alt="训练过程截图"><figcaption>训练过程截图</figcaption></figure></li><li><p>模型评估（根目录同上）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">注意：</span><br><span class="line"><span class="number">1.</span> legacy/evaluator.py 第<span class="number">58</span>行改为 ：EVAL_DEFAULT_METRIC = <span class="string">'coco_detection_metrics'</span></span><br><span class="line"><span class="number">2.</span> utils/object_detection_evaluation.py 如果用python3的话将 unicode 改成str</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/legacy/eval.py </span><br><span class="line">        --logtostderr </span><br><span class="line">        --checkpoint_dir=object_detection/faster_rcnn_nas_coco_2018_01_28 </span><br><span class="line">        --eval_dir=object_detection/data/coco/ </span><br><span class="line">        --pipeline_config_path=object_detection/samples/configs/faster_rcnn_nas_coco.config </span><br><span class="line">        --run_once True</span><br></pre></td></tr></table></figure><figure><img src="/images/eval_result.png" alt="测试结果–简略版"><figcaption>测试结果–简略版</figcaption></figure></li></ul><h3 id="在voc上微调">3. 在VOC上微调</h3><ol type="1"><li>构建VOC TFRcord格式数据</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/dataset_tools/create_pascal_tf_record.py \</span><br><span class="line">        --data_dir=/mnt/fpan/HBL_data/data_set/VOCdevkit \</span><br><span class="line">        --year=VOC2007 \</span><br><span class="line">        --output_path=object_detection/data/voc/train2007.record   <span class="comment">#是文件名</span></span><br></pre></td></tr></table></figure><ol start="2" type="1"><li><p>重新写一个object_detection/samples/configs/faster_rcnn_nas_voc.config 文件</p><p>在 fine_tune_checkpoint：设置为COCO训练好的模型权重路径。</p><p>测试方法同上</p></li></ol><h3 id="faster-rcnn-nasnet-demo">4. Faster RCNN Nasnet demo</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">见object_detection_tutorial.py 该文件需要在object detection目录下或者你把里面的路径设置正确</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # Object Detection Demo</span></span><br><span class="line"><span class="comment"># Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> six.moves.urllib <span class="keyword">as</span> urllib</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> distutils.version <span class="keyword">import</span> StrictVersion</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> StringIO</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># This is needed since the notebook is stored in the object_detection folder.</span></span><br><span class="line">sys.path.append(<span class="string">".."</span>)</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> ops <span class="keyword">as</span> utils_ops</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> StrictVersion(tf.__version__) &lt; StrictVersion(<span class="string">'1.9.0'</span>):</span><br><span class="line">  <span class="keyword">raise</span> ImportError(<span class="string">'Please upgrade your TensorFlow installation to v1.9.* or later!'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Env setup</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This is needed to display the images.</span></span><br><span class="line"><span class="comment">#get_ipython().magic('matplotlib inline')</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Object detection imports</span></span><br><span class="line"><span class="comment"># Here are the imports from the object detection module.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> label_map_util</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> visualization_utils <span class="keyword">as</span> vis_util</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # Model preparation </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Variables</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_FROZEN_GRAPH` to point to a new .pb file.  </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># By default we use an "SSD with Mobilenet" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># What model to download.</span></span><br><span class="line">MODEL_NAME = <span class="string">'faster_rcnn_nas_coco_2018_01_28'</span></span><br><span class="line">MODEL_FILE = MODEL_NAME + <span class="string">'.tar.gz'</span></span><br><span class="line">DOWNLOAD_BASE = <span class="string">'http://download.tensorflow.org/models/object_detection/'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Path to frozen detection graph. This is the actual model that is used for the object detection.</span></span><br><span class="line">PATH_TO_FROZEN_GRAPH = MODEL_NAME + <span class="string">'/frozen_inference_graph.pb'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List of the strings that is used to add correct label for each box.</span></span><br><span class="line">PATH_TO_LABELS = os.path.join(<span class="string">'data'</span>, <span class="string">'mscoco_label_map.pbtxt'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Download Model</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># opener = urllib.request.URLopener()</span></span><br><span class="line"><span class="comment"># opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)</span></span><br><span class="line"><span class="comment"># tar_file = tarfile.open(MODEL_FILE)</span></span><br><span class="line"><span class="comment"># for file in tar_file.getmembers():</span></span><br><span class="line"><span class="comment">#  file_name = os.path.basename(file.name)</span></span><br><span class="line"><span class="comment">#  if 'frozen_inference_graph.pb' in file_name:</span></span><br><span class="line"><span class="comment">#    tar_file.extract(file, os.getcwd())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Load a (frozen) Tensorflow model into memory.</span></span><br><span class="line"></span><br><span class="line">detection_graph = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">  od_graph_def = tf.GraphDef()</span><br><span class="line">  <span class="keyword">with</span> tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, <span class="string">'rb'</span>) <span class="keyword">as</span> fid:</span><br><span class="line">    serialized_graph = fid.read()</span><br><span class="line">    od_graph_def.ParseFromString(serialized_graph)</span><br><span class="line">    tf.import_graph_def(od_graph_def, name=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ## Loading label map</span></span><br><span class="line"><span class="comment"># Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine</span></span><br><span class="line">category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_image_into_numpy_array</span><span class="params">(image)</span>:</span></span><br><span class="line">  (im_width, im_height) = image.size</span><br><span class="line">  <span class="keyword">return</span> np.array(image.getdata()).reshape(</span><br><span class="line">      (im_height, im_width, <span class="number">3</span>)).astype(np.uint8)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># # Detection</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For the sake of simplicity we will use only 2 images:</span></span><br><span class="line"><span class="comment"># image1.jpg</span></span><br><span class="line"><span class="comment"># image2.jpg</span></span><br><span class="line"><span class="comment"># If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.</span></span><br><span class="line">PATH_TO_TEST_IMAGES_DIR = <span class="string">'test_images'</span></span><br><span class="line">TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, <span class="string">'image&#123;&#125;.jpg'</span>.format(i)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">3</span>) ]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Size, in inches, of the output images.</span></span><br><span class="line">IMAGE_SIZE = (<span class="number">12</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run_inference_for_single_image</span><span class="params">(image, graph)</span>:</span></span><br><span class="line">  <span class="keyword">with</span> graph.as_default():</span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">      <span class="comment"># Get handles to input and output tensors</span></span><br><span class="line">      ops = tf.get_default_graph().get_operations()</span><br><span class="line">      all_tensor_names = &#123;output.name <span class="keyword">for</span> op <span class="keyword">in</span> ops <span class="keyword">for</span> output <span class="keyword">in</span> op.outputs&#125;</span><br><span class="line">      tensor_dict = &#123;&#125;</span><br><span class="line">      <span class="keyword">for</span> key <span class="keyword">in</span> [</span><br><span class="line">          <span class="string">'num_detections'</span>, <span class="string">'detection_boxes'</span>, <span class="string">'detection_scores'</span>,</span><br><span class="line">          <span class="string">'detection_classes'</span>, <span class="string">'detection_masks'</span></span><br><span class="line">      ]:</span><br><span class="line">        tensor_name = key + <span class="string">':0'</span></span><br><span class="line">        <span class="keyword">if</span> tensor_name <span class="keyword">in</span> all_tensor_names:</span><br><span class="line">          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(</span><br><span class="line">              tensor_name)</span><br><span class="line">      <span class="keyword">if</span> <span class="string">'detection_masks'</span> <span class="keyword">in</span> tensor_dict:</span><br><span class="line">        <span class="comment"># The following processing is only for single image</span></span><br><span class="line">        detection_boxes = tf.squeeze(tensor_dict[<span class="string">'detection_boxes'</span>], [<span class="number">0</span>])</span><br><span class="line">        detection_masks = tf.squeeze(tensor_dict[<span class="string">'detection_masks'</span>], [<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.</span></span><br><span class="line">        real_num_detection = tf.cast(tensor_dict[<span class="string">'num_detections'</span>][<span class="number">0</span>], tf.int32)</span><br><span class="line">        detection_boxes = tf.slice(detection_boxes, [<span class="number">0</span>, <span class="number">0</span>], [real_num_detection, <span class="number">-1</span>])</span><br><span class="line">        detection_masks = tf.slice(detection_masks, [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [real_num_detection, <span class="number">-1</span>, <span class="number">-1</span>])</span><br><span class="line">        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(</span><br><span class="line">            detection_masks, detection_boxes, image.shape[<span class="number">0</span>], image.shape[<span class="number">1</span>])</span><br><span class="line">        detection_masks_reframed = tf.cast(</span><br><span class="line">            tf.greater(detection_masks_reframed, <span class="number">0.5</span>), tf.uint8)</span><br><span class="line">        <span class="comment"># Follow the convention by adding back the batch dimension</span></span><br><span class="line">        tensor_dict[<span class="string">'detection_masks'</span>] = tf.expand_dims(</span><br><span class="line">            detection_masks_reframed, <span class="number">0</span>)</span><br><span class="line">      image_tensor = tf.get_default_graph().get_tensor_by_name(<span class="string">'image_tensor:0'</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Run inference</span></span><br><span class="line">      output_dict = sess.run(tensor_dict,</span><br><span class="line">                             feed_dict=&#123;image_tensor: np.expand_dims(image, <span class="number">0</span>)&#125;)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># all outputs are float32 numpy arrays, so convert types as appropriate</span></span><br><span class="line">      output_dict[<span class="string">'num_detections'</span>] = int(output_dict[<span class="string">'num_detections'</span>][<span class="number">0</span>])</span><br><span class="line">      output_dict[<span class="string">'detection_classes'</span>] = output_dict[</span><br><span class="line">          <span class="string">'detection_classes'</span>][<span class="number">0</span>].astype(np.uint8)</span><br><span class="line">      output_dict[<span class="string">'detection_boxes'</span>] = output_dict[<span class="string">'detection_boxes'</span>][<span class="number">0</span>]</span><br><span class="line">      output_dict[<span class="string">'detection_scores'</span>] = output_dict[<span class="string">'detection_scores'</span>][<span class="number">0</span>]</span><br><span class="line">      <span class="keyword">if</span> <span class="string">'detection_masks'</span> <span class="keyword">in</span> output_dict:</span><br><span class="line">        output_dict[<span class="string">'detection_masks'</span>] = output_dict[<span class="string">'detection_masks'</span>][<span class="number">0</span>]</span><br><span class="line">  <span class="keyword">return</span> output_dict</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image_path <span class="keyword">in</span> TEST_IMAGE_PATHS:</span><br><span class="line">  image = Image.open(image_path)</span><br><span class="line">  <span class="comment"># the array based representation of the image will be used later in order to prepare the</span></span><br><span class="line">  <span class="comment"># result image with boxes and labels on it.</span></span><br><span class="line">  image_np = load_image_into_numpy_array(image)</span><br><span class="line">  <span class="comment"># Expand dimensions since the model expects images to have shape: [1, None, None, 3]</span></span><br><span class="line">  image_np_expanded = np.expand_dims(image_np, axis=<span class="number">0</span>)</span><br><span class="line">  <span class="comment"># Actual detection.</span></span><br><span class="line">  output_dict = run_inference_for_single_image(image_np, detection_graph)</span><br><span class="line">  <span class="comment"># Visualization of the results of a detection.</span></span><br><span class="line">  vis_util.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">      image_np,</span><br><span class="line">      output_dict[<span class="string">'detection_boxes'</span>],</span><br><span class="line">      output_dict[<span class="string">'detection_classes'</span>],</span><br><span class="line">      output_dict[<span class="string">'detection_scores'</span>],</span><br><span class="line">      category_index,</span><br><span class="line">      instance_masks=output_dict.get(<span class="string">'detection_masks'</span>),</span><br><span class="line">      use_normalized_coordinates=<span class="keyword">True</span>,</span><br><span class="line">      line_thickness=<span class="number">8</span>)</span><br><span class="line">  plt.figure(figsize=IMAGE_SIZE)</span><br><span class="line">  plt.imshow(image_np)</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> Object Detection </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Faster RCNN </tag>
            
            <tag> Tensorflow </tag>
            
            <tag> COCO </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>并发编程</title>
      <link href="/2018/08/28/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"/>
      <url>/2018/08/28/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</url>
      <content type="html"><![CDATA[<p>  首先感谢况老师的指导和潇哥的指点。以下内容来自初学的我，谨防入坑！</p><p>  促使我对并发/并行操作的关注是我对python同步多线程和异步多线程的理解空白，导致我2个月前的一次失败的同步多线程操作直到昨天改keras的imge处理底层代码时发现还有异步多线程实现的并发操作。在此记录下并发操作相关概念和理解。</p><p>  理解python的并发操作需要掌握python的全局解释器锁(GIL)以及多进程、多线程操作和协程操作。相关概念的区别如阻塞和非阻塞、并发和并行、同步和异步、计算操作密集和I/O密集的概念和区分。本文重点区分上述概念。 <a id="more"></a></p><h2 id="python为什么比cjava慢">python为什么比C++/Java慢</h2><p>  首先C++和Java是编译型语言，而Python则是一种解释型语言。编译型语言在程序执行前需要一个专门编译额过程，将代码编译成机器语言；而python是解释型语言不需要编译，在程序执行时将代码一步步翻译成机器语言。python的变量类型是动态的，解释器会根据程序将变量和所有的变量类型存放在内存中；而静态类型直接将变量与其类型绑定。形象的理解是python解释器制定规则，python执行代码时去匹配这个规则，然后再执行。</p><h2 id="全局解释器锁gil">全局解释器锁(GIL)</h2><p>  为了利用多核系统，Python必须支持多线程运行。但作为解释型语言，Python的解释器需要做到既安全又高效。解释器要注意避免在不同的线程操作内部共享的数据，同时还要保证在管理用户线程时保证总是有最大化的计算资源。为了保证不同线程同时访问数据时的安全性，Python使用了<strong>全局解释器锁(GIL)</strong>的机制。从名字上我们很容易明白，它是一个加在解释器上的全局（从解释器的角度看）锁（从互斥或者类似角度看）。这种方式当然很安全，但它也意味着：<strong>对于任何Python程序，不管有多少的处理器，任何时候都总是只有一个线程在执行</strong>。即：只有获得了全局解释器锁的线程才能操作Python对象或者调用Python/C API函数。</p><h2 id="python的gil">Python的GIL</h2><ul><li>CPython的线程是<a href="https://zh.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F" target="_blank" rel="noopener">操作系统</a>的原生线程。在<a href="https://zh.wikipedia.org/wiki/Linux" target="_blank" rel="noopener">Linux</a>上为pthread，在<a href="https://zh.wikipedia.org/wiki/Windows" target="_blank" rel="noopener">Windows</a>上为Win thread，完全由操作系统调度线程的执行。一个Python解释器进程内有一个主线程，以及多个用户程序的执行线程。即便使用<a href="https://zh.wikipedia.org/wiki/%E5%A4%9A%E6%A0%B8%E5%BF%83CPU" target="_blank" rel="noopener">多核心CPU</a>平台，由于GIL的存在，也将禁止多线程的并行执行。</li><li>Python解释器进程内的多线程是以协作多任务方式执行。<strong><em>当一个线程遇到<a href="https://zh.wikipedia.org/wiki/I/O" target="_blank" rel="noopener">I/O</a>任务时，将释放GIL</em></strong>。计算密集型（CPU-bound）的线程在执行大约100次解释器的计步（ticks）时，将释放GIL。计步（ticks）可粗略看作Python虚拟机的指令。计步实际上与时间片长度无关。可以通过sys.setcheckinterval()设置计步长度。</li><li>在单核CPU上，数百次的间隔检查才会导致一次线程切换。在多核CPU上，存在严重的线程抖动（thrashing）。</li><li>Python 3.2开始使用新的GIL。新的GIL实现中用一个固定的超时时间来指示当前的线程放弃全局锁。在当前线程保持这个锁，且其他线程请求这个锁时，当前线程就会在5毫秒后被强制释放该锁。</li><li>可以创建独立的进程来实现并行化。Python 2.6引进了多进程包multiprocessing。或者将关键组件用<a href="https://zh.wikipedia.org/wiki/C%E8%AF%AD%E8%A8%80" target="_blank" rel="noopener">C</a>/<a href="https://zh.wikipedia.org/wiki/C%2B%2B" target="_blank" rel="noopener">C++</a>编写为Python扩展，通过ctypes使Python程序直接调用C语言<a href="https://zh.wikipedia.org/wiki/%E7%BC%96%E8%AF%91" target="_blank" rel="noopener">编译</a>的<a href="https://zh.wikipedia.org/wiki/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%BA%93" target="_blank" rel="noopener">动态链接库</a>的导出函数。【来自维基百科】</li></ul><p><strong><em>小结</em></strong>：</p><ol type="1"><li>由于GIL的存在，一个python解释器进程执行多线程时实际上也只是在保护一个主线程的运行。</li><li>I/O操作主要是读写任务，CPU操作主要是计算任务，当python执行I/O密集型任务，将释放GIL开多线程仍然可以通过让其他线程加快程序运行效率。如果是cpu密集型任务，线程切换导致cache missing造成不必要的开销切换，反而影响程序效率。<strong>在keras图像预处理接口keras.preprocessing.image中实现多线程读取文件夹名和文件名操作然后分批，在读取分批数据以达到减小内存的作用的</strong></li></ol><h2 id="进程">进程</h2><p>  进程之间不共享任何状态，进程的调度由操作系统完成，每个进程都有自己独立的内存空间，进程间通讯主要是通过信号传递的方式来实现的，实现方式有多种，信号量、管道、事件等，任何一种方式的通讯效率都需要过内核，导致通讯效率比较低。由于是独立的内存空间，上下文切换的时候需要保存先调用栈的信息、cpu各寄存器的信息、虚拟内存、以及打开的相关句柄等信息，所以导致上下文进程间切换开销很大，通讯麻烦。</p><p>  简单来讲，每一个应用程序都有一个自己的进程。 操作系统会为这些进程分配一些执行资源，例如内存空间等。 在进程中，又可以创建一些线程，他们共享这些内存空间，并由操作系统调用， 以便并行计算。</p><h3 id="创建进程">创建进程</h3><p>  Python2.6以后提供了非常好用的多进程包multiprocessing，只需要定义一个函数，Python会完成其他所有事情。multiprocessing给每个进程赋予单独的Python解释器，这样就规避了全局解释锁所带来的问题。借助这个包，可以轻松完成从单进程到并发执行的转换。</p><p>  multiprocessing支持子进程、通信和共享数据、执行不同形式的同步，提供了Process、Queue、Pipe、Lock等组件。<strong>具体的细节以后再说吧，实践很少就是全记下来了也记不久留个坑；以后有需求了再补充：进程通信，锁，列队，进程通信管道等</strong>。</p><p>用multiprocessing开启进程，其代码块必须放在<code>if __name__ == '__main__':</code>下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_process</span><span class="params">(name)</span>:</span></span><br><span class="line">    print(<span class="string">'%s cur ele'</span> %name)</span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br><span class="line">    print(<span class="string">'%s cur ele end'</span> %name)</span><br><span class="line"><span class="comment"># 进程开启必须放在main()下，multiprocessing为每个进程开一个解释器</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> (<span class="string">'ele1'</span>, <span class="string">'ele2'</span>, <span class="string">'ele3'</span>):</span><br><span class="line">        p = Process(target=start_process, args=(i,))</span><br><span class="line">        p.start()</span><br><span class="line">    print(<span class="string">'主进程'</span>)</span><br><span class="line"> <span class="string">"""OUTPUT</span></span><br><span class="line"><span class="string"> 主进程</span></span><br><span class="line"><span class="string">ele1 cur ele</span></span><br><span class="line"><span class="string">ele2 cur ele</span></span><br><span class="line"><span class="string">ele3 cur ele</span></span><br><span class="line"><span class="string">ele1 cur ele end</span></span><br><span class="line"><span class="string">ele2 cur ele end</span></span><br><span class="line"><span class="string">ele3 cur ele end</span></span><br><span class="line"><span class="string"> """</span></span><br><span class="line"><span class="comment">#没有time.sleep</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_process</span><span class="params">(name)</span>:</span></span><br><span class="line">    print(<span class="string">'%s cur ele'</span> %name)</span><br><span class="line"><span class="comment">#    time.sleep(3)</span></span><br><span class="line">    print(<span class="string">'%s cur ele end'</span> %name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:  <span class="comment"># 进程开启必须放在main()下</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> (<span class="string">'ele1'</span>, <span class="string">'ele2'</span>, <span class="string">'ele3'</span>):</span><br><span class="line">        p = Process(target=start_process, args=(i,))</span><br><span class="line">        p.start()</span><br><span class="line">    print(<span class="string">'主进程'</span>)</span><br><span class="line"> <span class="string">"""</span></span><br><span class="line"><span class="string"> 主进程</span></span><br><span class="line"><span class="string">ele1 cur ele</span></span><br><span class="line"><span class="string">ele1 cur ele end</span></span><br><span class="line"><span class="string">ele2 cur ele</span></span><br><span class="line"><span class="string">ele2 cur ele end</span></span><br><span class="line"><span class="string">ele3 cur ele</span></span><br><span class="line"><span class="string">ele3 cur ele end</span></span><br><span class="line"><span class="string"> """</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">start_process</span><span class="params">(Process)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'%s cur ele'</span> %self.name)</span><br><span class="line">        time.sleep(<span class="number">3</span>)</span><br><span class="line">        print(<span class="string">'%s cur ele'</span> %self.name)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:  <span class="comment"># 进程开启必须放在main()下</span></span><br><span class="line">    print(<span class="string">"CPU个数："</span>,cpu_count())</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> (<span class="string">'ele1'</span>, <span class="string">'ele2'</span>, <span class="string">'ele3'</span>,<span class="string">'ele4'</span>,<span class="string">'ele5'</span>):</span><br><span class="line">        p = start_process(i,)</span><br><span class="line">        p.start()</span><br><span class="line">        p.join()<span class="comment">#加入进程同步</span></span><br><span class="line">    print(<span class="string">'主进程'</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">CPU个数： 4</span></span><br><span class="line"><span class="string">ele1 cur ele</span></span><br><span class="line"><span class="string">ele1 cur ele</span></span><br><span class="line"><span class="string">ele2 cur ele</span></span><br><span class="line"><span class="string">ele2 cur ele</span></span><br><span class="line"><span class="string">ele3 cur ele</span></span><br><span class="line"><span class="string">ele3 cur ele</span></span><br><span class="line"><span class="string">ele4 cur ele</span></span><br><span class="line"><span class="string">ele4 cur ele</span></span><br><span class="line"><span class="string">ele5 cur ele</span></span><br><span class="line"><span class="string">ele5 cur ele</span></span><br><span class="line"><span class="string">主进程</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="进程池">进程池</h3><p>  进程池就是预先创建进程，需要的时候就从进程池拿，进程的创建和销毁统一由进程池管理。Pool可以提供指定数量的进程，供用户调用，当有新的请求提交到pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来它。python内置的multiprocessing.pool实现进程池管理。<strong>在python官方文档里显示该功能在交互式解释器中并不能完好运行，而且实践发现spyder不打印子进程输出 。</strong></p><h2 id="线程">线程</h2><p>  操作系统为进程分配执行的资源比如内存空间，而线程就在进程下面共享进程的资源。多线程可以处理多进程访问同一资源麻烦的问题。</p><h3 id="创建线程">创建线程</h3><p>  Python提供两个模块进行多线程的操作，分别是<code>thread</code>和<code>threading</code>，前者是比较低级的模块，用于更底层的操作，一般应用级别的开发不常用。</p><p>第一种方法是创建<code>threading.Thread</code>的子类，重写<code>run</code>方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.name = name</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">'thread &#123;&#125;, @number: &#123;&#125;'</span>.format(self.name, i))</span><br><span class="line">            time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"Start main threading"</span>)</span><br><span class="line">    <span class="comment"># 创建三个线程</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        threads = MyThread(<span class="string">"thread-%i"</span>%i) </span><br><span class="line">    <span class="comment"># 启动三个线程</span></span><br><span class="line">    threads.start()</span><br><span class="line">    threads.join()       </span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"End Main threading"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"=======创建同步三个线程======="</span>)</span><br><span class="line">    main()</span><br><span class="line">    print(<span class="string">"=======创建异步多线程======="</span>)</span><br><span class="line">    threads = [MyThread(<span class="string">"thread-%i"</span>%i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>)]</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> threads:</span><br><span class="line">        t.start()</span><br><span class="line">    <span class="comment"># 一次让新创建的线程执行 join</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> threads:</span><br><span class="line">        t.join()</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"End Async Main threading"</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">受GIL控制同步时由一个线程控制，多进程在等待上个进程时受系统调度已经开始执行了</span></span><br><span class="line"><span class="string">异步多线程在等待时执行了下一个线程</span></span><br><span class="line"><span class="string">=======创建同步三个线程=======</span></span><br><span class="line"><span class="string">Start main threading</span></span><br><span class="line"><span class="string">thread thread-2, @number: 0</span></span><br><span class="line"><span class="string">thread thread-2, @number: 1</span></span><br><span class="line"><span class="string">thread thread-2, @number: 2</span></span><br><span class="line"><span class="string">thread thread-2, @number: 3</span></span><br><span class="line"><span class="string">thread thread-2, @number: 4</span></span><br><span class="line"><span class="string">End Main threading</span></span><br><span class="line"><span class="string">=======创建异步多线程=======</span></span><br><span class="line"><span class="string">thread thread-0, @number: 0</span></span><br><span class="line"><span class="string">thread thread-1, @number: 0</span></span><br><span class="line"><span class="string">thread thread-2, @number: 0</span></span><br><span class="line"><span class="string">thread thread-0, @number: 1</span></span><br><span class="line"><span class="string">thread thread-1, @number: 1</span></span><br><span class="line"><span class="string">thread thread-2, @number: 1</span></span><br><span class="line"><span class="string">thread thread-0, @number: 2</span></span><br><span class="line"><span class="string">thread thread-1, @number: 2</span></span><br><span class="line"><span class="string">thread thread-2, @number: 2</span></span><br><span class="line"><span class="string">thread thread-0, @number: 3</span></span><br><span class="line"><span class="string">thread thread-1, @number: 3</span></span><br><span class="line"><span class="string">thread thread-2, @number: 3</span></span><br><span class="line"><span class="string">thread thread-0, @number: 4</span></span><br><span class="line"><span class="string">thread thread-2, @number: 4</span></span><br><span class="line"><span class="string">thread thread-1, @number: 4</span></span><br><span class="line"><span class="string">End Async Main threading</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h3 id="线程池">线程池</h3><p>  线程池的出发点和进程池类似，线程为了控制和管理线程即创建和销毁。具体的将线程放进一个池子，一方面我们可以控制同时工作的线程数量，一方面也避免了创建和销毁产生的开销。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> queue</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">double</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> n * <span class="number">2</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Worker</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, queue)</span>:</span></span><br><span class="line">        super(Worker, self).__init__()</span><br><span class="line">        self._q = queue</span><br><span class="line">        self.daemon = <span class="keyword">True</span></span><br><span class="line">        self.start()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">            f, args, kwargs = self._q.get()</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                print(<span class="string">'USE:&#123;&#125;'</span>.format(self.name))</span><br><span class="line">                print(f(*args, **kwargs))</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                print(e)</span><br><span class="line">            self._q.task_done()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ThreadPool</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, max_num=<span class="number">5</span>)</span>:</span></span><br><span class="line">        self._q = queue.Queue(max_num)</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(max_num):</span><br><span class="line">            Worker(self._q)  <span class="comment"># create worker thread</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_task</span><span class="params">(self, f, *args, **kwargs)</span>:</span></span><br><span class="line">        self._q.put((f, args, kwargs))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wait_compelete</span><span class="params">(self)</span>:</span></span><br><span class="line">        self._q.join()</span><br><span class="line"></span><br><span class="line">pool = ThreadPool()</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">8</span>):</span><br><span class="line">    wt = random()</span><br><span class="line">    pool.add_task(double, wt)</span><br><span class="line">    time.sleep(wt)</span><br><span class="line"></span><br><span class="line">pool.wait_compelete()</span><br></pre></td></tr></table></figure><h2 id="多进程和多线程的计算开销">多进程和多线程的计算开销</h2><p><a href="https://blog.csdn.net/SecondLieutenant/article/details/79396984" target="_blank" rel="noopener">code</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process , Queue , cpu_count</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 定义全局变量Queue</span></span><br><span class="line">g_queue = Queue()</span><br><span class="line"><span class="comment"># 定义一个队列，并定义初始化队列的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_queue</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"init g_queue start"</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        g_queue.get()</span><br><span class="line">    <span class="keyword">for</span> _index <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        g_queue.put(_index)</span><br><span class="line">    print(<span class="string">"init g_queue end"</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 定义IO密集型任务和计算密集型任务，分别从队列中获取任务数据</span></span><br><span class="line"><span class="comment"># 定义一个IO密集型任务：利用time.sleep()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_io</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"IOTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="keyword">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"IOTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"IOTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"IOTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"> </span><br><span class="line">g_search_list = list(range(<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># 定义一个计算密集型任务：利用一些复杂加减乘除、列表查找等</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_cpu</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"CPUTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">            count += pow(<span class="number">3</span>*<span class="number">2</span>, <span class="number">3</span>*<span class="number">2</span>) <span class="keyword">if</span> i <span class="keyword">in</span> g_search_list <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="keyword">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"CPUTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"CPUTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"CPUTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span> task_id</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"cpu count:"</span>, cpu_count(), <span class="string">"\n"</span>)</span><br><span class="line"> </span><br><span class="line">    print(<span class="string">"========== 直接执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_io(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"> </span><br><span class="line">    print(<span class="string">"========== 多线程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [Thread(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>)]</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"> </span><br><span class="line">    print(<span class="string">"========== 多进程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [Process(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(cpu_count())]</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"> </span><br><span class="line">    print(<span class="string">"========== 直接执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_cpu(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"> </span><br><span class="line">    print(<span class="string">"========== 多线程执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [Thread(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>)]</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"> </span><br><span class="line">    print(<span class="string">"========== 多进程执行cpu密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [Process(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(cpu_count())]</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">cpu count: 4</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">========== 直接执行IO密集型任务 ==========</span></span><br><span class="line"><span class="string">init g_queue start</span></span><br><span class="line"><span class="string">init g_queue end</span></span><br><span class="line"><span class="string">IOTask[0] start</span></span><br><span class="line"><span class="string">IOTask[0] get data: 0</span></span><br><span class="line"><span class="string">IOTask[0] get data: 1</span></span><br><span class="line"><span class="string">IOTask[0] get data: 2</span></span><br><span class="line"><span class="string">IOTask[0] get data: 3</span></span><br><span class="line"><span class="string">IOTask[0] get data: 4</span></span><br><span class="line"><span class="string">IOTask[0] get data: 5</span></span><br><span class="line"><span class="string">IOTask[0] get data: 6</span></span><br><span class="line"><span class="string">IOTask[0] get data: 7</span></span><br><span class="line"><span class="string">IOTask[0] get data: 8</span></span><br><span class="line"><span class="string">IOTask[0] get data: 9</span></span><br><span class="line"><span class="string">IOTask[0] end</span></span><br><span class="line"><span class="string">结束： 10.0093834400177</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">========== 多线程执行IO密集型任务 ==========</span></span><br><span class="line"><span class="string">init g_queue start</span></span><br><span class="line"><span class="string">init g_queue end</span></span><br><span class="line"><span class="string">IOTask[0] start</span></span><br><span class="line"><span class="string">IOTask[1] start</span></span><br><span class="line"><span class="string">IOTask[2] start</span></span><br><span class="line"><span class="string">IOTask[3] start</span></span><br><span class="line"><span class="string">IOTask[4] start</span></span><br><span class="line"><span class="string">IOTask[0] get data: 0</span></span><br><span class="line"><span class="string">IOTask[1] get data: 1</span></span><br><span class="line"><span class="string">IOTask[2] get data: 2</span></span><br><span class="line"><span class="string">IOTask[3] get data: 3</span></span><br><span class="line"><span class="string">IOTask[4] get data: 4</span></span><br><span class="line"><span class="string">IOTask[0] get data: 5</span></span><br><span class="line"><span class="string">IOTask[1] get data: 6</span></span><br><span class="line"><span class="string">IOTask[3] get data: 7</span></span><br><span class="line"><span class="string">IOTask[2] get data: 8</span></span><br><span class="line"><span class="string">IOTask[4] get data: 9</span></span><br><span class="line"><span class="string">IOTask[2] end</span></span><br><span class="line"><span class="string">IOTask[4] end</span></span><br><span class="line"><span class="string">IOTask[0] error:</span></span><br><span class="line"><span class="string">IOTask[0] end</span></span><br><span class="line"><span class="string">IOTask[1] error:</span></span><br><span class="line"><span class="string">IOTask[1] end</span></span><br><span class="line"><span class="string">IOTask[3] error:</span></span><br><span class="line"><span class="string">IOTask[3] end</span></span><br><span class="line"><span class="string">结束： 4.019008159637451</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">========== 多进程执行IO密集型任务 ==========</span></span><br><span class="line"><span class="string">init g_queue start</span></span><br><span class="line"><span class="string">init g_queue end</span></span><br><span class="line"><span class="string">IOTask[3] start</span></span><br><span class="line"><span class="string">IOTask[3] end</span></span><br><span class="line"><span class="string">IOTask[0] start</span></span><br><span class="line"><span class="string">IOTask[0] end</span></span><br><span class="line"><span class="string">IOTask[1] start</span></span><br><span class="line"><span class="string">IOTask[1] end</span></span><br><span class="line"><span class="string">IOTask[2] start</span></span><br><span class="line"><span class="string">IOTask[2] end</span></span><br><span class="line"><span class="string">结束： 0.2742750644683838</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">========== 直接执行CPU密集型任务 ==========</span></span><br><span class="line"><span class="string">init g_queue start</span></span><br><span class="line"><span class="string">init g_queue end</span></span><br><span class="line"><span class="string">CPUTask[0] start</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 0</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 1</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 2</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 3</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 4</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 5</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 6</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 7</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 8</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 9</span></span><br><span class="line"><span class="string">CPUTask[0] end</span></span><br><span class="line"><span class="string">结束： 8.974508285522461</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">========== 多线程执行CPU密集型任务 ==========</span></span><br><span class="line"><span class="string">init g_queue start</span></span><br><span class="line"><span class="string">init g_queue end</span></span><br><span class="line"><span class="string">CPUTask[0] start</span></span><br><span class="line"><span class="string">CPUTask[1] start</span></span><br><span class="line"><span class="string">CPUTask[2] start</span></span><br><span class="line"><span class="string">CPUTask[3] start</span></span><br><span class="line"><span class="string">CPUTask[4] start</span></span><br><span class="line"><span class="string">CPUTask[1] get data: 0</span></span><br><span class="line"><span class="string">CPUTask[3] get data: 1</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 2</span></span><br><span class="line"><span class="string">CPUTask[2] get data: 3</span></span><br><span class="line"><span class="string">CPUTask[4] get data: 4</span></span><br><span class="line"><span class="string">CPUTask[1] get data: 5</span></span><br><span class="line"><span class="string">CPUTask[3] get data: 6</span></span><br><span class="line"><span class="string">CPUTask[2] get data: 7</span></span><br><span class="line"><span class="string">CPUTask[0] get data: 8</span></span><br><span class="line"><span class="string">CPUTask[4] get data: 9</span></span><br><span class="line"><span class="string">CPUTask[4] end</span></span><br><span class="line"><span class="string">CPUTask[1] error:</span></span><br><span class="line"><span class="string">CPUTask[1] end</span></span><br><span class="line"><span class="string">CPUTask[2] error:</span></span><br><span class="line"><span class="string">CPUTask[2] end</span></span><br><span class="line"><span class="string">CPUTask[3] error:</span></span><br><span class="line"><span class="string">CPUTask[3] end</span></span><br><span class="line"><span class="string">CPUTask[0] error:</span></span><br><span class="line"><span class="string">CPUTask[0] end</span></span><br><span class="line"><span class="string">结束： 13.33148455619812</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">========== 多进程执行cpu密集型任务 ==========</span></span><br><span class="line"><span class="string">init g_queue start</span></span><br><span class="line"><span class="string">init g_queue end</span></span><br><span class="line"><span class="string">CPUTask[1] start</span></span><br><span class="line"><span class="string">CPUTask[1] end</span></span><br><span class="line"><span class="string">CPUTask[2] start</span></span><br><span class="line"><span class="string">CPUTask[2] end</span></span><br><span class="line"><span class="string">CPUTask[3] start</span></span><br><span class="line"><span class="string">CPUTask[3] end</span></span><br><span class="line"><span class="string">CPUTask[0] start</span></span><br><span class="line"><span class="string">CPUTask[0] end</span></span><br><span class="line"><span class="string">结束： 0.2652151584625244</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><h2 id="协程">协程</h2><p>  协程，又称微线程，纤程。英文名Coroutine。协程的概念很早就提出来了，但直到最近几年才在某些语言（如Lua）中得到广泛应用。<a href="https://www.cnblogs.com/vipchenwei/p/7809967.html" target="_blank" rel="noopener">协程描述部分来自博客园</a></p><p>  子程序，或者称为函数，在所有语言中都是层级调用，比如A调用B，B在执行过程中又调用了C，C执行完毕返回，B执行完毕返回，最后是A执行完毕。所以子程序调用是通过栈实现的，一个线程就是执行一个子程序。子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。</p><p>  协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。</p><p>　　<strong>线程和进程的操作是由程序触发系统接口，最后的执行者是系统；协程的操作则是程序员</strong></p><blockquote><p>　　协程的优点：</p><ul><li>无需线程上下文切换的开销</li><li>无需原子操作锁定及同步的开销</li><li>方便切换控制流，简化编程模型</li><li>高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。</li></ul><p>　　缺点：</p><ul><li>无法利用多核资源：协程的本质是个单线程,它不能同时将 单个CPU 的多个核用上,协程需要和进程配合才能运行在多CPU上.当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。</li><li>进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序</li></ul></blockquote><p>  Python中的协程和生成器很相似但又稍有不同。主要区别在于：</p><ul><li>生成器是数据的<code>生产者</code></li><li>协程则是数据的<code>消费者</code></li></ul><p>  在前面的博客中讲过生成器用yeild来实现动态的返回程序的结果，即实现了一个协程。协程会消费掉(拿去用)发送给它的值。</p><h2 id="生产者消费者模式">生产者消费者模式</h2><p>  生产者负责生产数据，存放在缓存区，而消费者负责从缓存区获得数据并处理数据。生产者消费者模式即将一件事分成流水线模型，生产者产生的输出交付给消费者处理，可以实现同一时刻，前后同时运行。</p><figure><img src="/images/生产者消费者.png" alt="生产者消费者模式"><figcaption>生产者消费者模式</figcaption></figure><p>生产者消费者模式的优点：</p><ul><li><blockquote><p><strong>解耦</strong> 假设生产者和消费者分别是两个线程。如果让生产者直接调用消费者的某个方法，那么生产者对于消费者就会产生依赖（也就是耦合）。如果未来消费者的代码发生变化，可能会影响到生产者的代码。而如果两者都依赖于某个缓冲区，两者之间不直接依赖，耦合也就相应降低了。</p></blockquote></li><li><blockquote><p><strong>并发</strong> 由于生产者与消费者是两个独立的并发体，他们之间是用缓冲区通信的，生产者只需要往缓冲区里丢数据，就可以继续生产下一个数据，而消费者只需要从缓冲区拿数据即可，这样就不会因为彼此的处理速度而发生阻塞。</p></blockquote></li><li><blockquote><p><strong>支持忙闲不均</strong> 当生产者制造数据快的时候，消费者来不及处理，未处理的数据可以暂时存在缓冲区中，慢慢处理掉。而不至于因为消费者的性能造成数据丢失或影响生产者生产。</p></blockquote></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> random,threading,time</span><br><span class="line"></span><br><span class="line"><span class="comment">#生产者类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Producer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name,queue)</span>:</span></span><br><span class="line">        threading.Thread.__init__(self, name=name)</span><br><span class="line">        self.data=queue</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">            print(<span class="string">"%s is producing %d to the queue!"</span> % (self.getName(), i))</span><br><span class="line">            self.data.put(i)<span class="comment">#将数据放入队列</span></span><br><span class="line">            time.sleep(random.randrange(<span class="number">10</span>)/<span class="number">5</span>)</span><br><span class="line">        print(<span class="string">"%s finished!"</span> % self.getName())</span><br><span class="line"></span><br><span class="line"><span class="comment">#消费者类</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Consumer</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,name,queue)</span>:</span></span><br><span class="line">        threading.Thread.__init__(self,name=name)</span><br><span class="line">        self.data=queue</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">            val = self.data.get()<span class="comment">#从队列中获取数据执行下面的操作</span></span><br><span class="line">            print(<span class="string">"%s is consuming. %d in the queue is consumed!"</span> % (self.getName(),val))</span><br><span class="line">            time.sleep(random.randrange(<span class="number">10</span>))</span><br><span class="line">        print(<span class="string">"%s finished!"</span> % self.getName())</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    queue = Queue()</span><br><span class="line">    producer = Producer(<span class="string">'Producer'</span>,queue)</span><br><span class="line">    consumer = Consumer(<span class="string">'Consumer'</span>,queue)</span><br><span class="line"></span><br><span class="line">    producer.start()</span><br><span class="line">    consumer.start()</span><br><span class="line"></span><br><span class="line">    producer.join()</span><br><span class="line">    consumer.join()</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'All threads finished!'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br><span class="line"> <span class="string">"""</span></span><br><span class="line"><span class="string">Producer is producing 0 to the queue!</span></span><br><span class="line"><span class="string">Consumer is consuming. 0 in the queue is consumed!</span></span><br><span class="line"><span class="string">Producer is producing 1 to the queue!</span></span><br><span class="line"><span class="string">Producer is producing 2 to the queue!</span></span><br><span class="line"><span class="string">Consumer is consuming. 1 in the queue is consumed!</span></span><br><span class="line"><span class="string">Producer is producing 3 to the queue!</span></span><br><span class="line"><span class="string">Producer is producing 4 to the queue!</span></span><br><span class="line"><span class="string">Producer finished!</span></span><br><span class="line"><span class="string">Consumer is consuming. 2 in the queue is consumed!</span></span><br><span class="line"><span class="string">Consumer is consuming. 3 in the queue is consumed!</span></span><br><span class="line"><span class="string">Consumer is consuming. 4 in the queue is consumed!</span></span><br><span class="line"><span class="string">Consumer finished!All threads finished!</span></span><br><span class="line"><span class="string"> """</span></span><br></pre></td></tr></table></figure><h2 id="阻塞与非阻塞">阻塞与非阻塞</h2><p>  阻塞是指调用线程或者进程被操作系统挂起。 非阻塞是指调用线程或者进程不会被操作系统挂起。</p><h2 id="同步与异步">同步与异步</h2><p>同步是指代码调用IO操作时，必须等待IO操作完成才返回的调用方式。 异步是指代码调用IO操作时，不必等IO操作完成就返回的调用方式。</p><p>同步是最原始的调用方式。 异步则需要多线程，多CPU或者非阻塞IO的支持。</p><p>  在multiprocessing中通常用apply/map和apply_async/map_async函数完成同步异步(阻塞和非阻塞)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">从keras image剥离的文件夹处理的源码，用阻塞和非阻塞方式实现并发操作</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> linalg</span><br><span class="line"><span class="keyword">import</span> scipy.ndimage <span class="keyword">as</span> ndi</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> range</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line"><span class="keyword">import</span> multiprocessing.pool</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> PIL <span class="keyword">import</span> Image <span class="keyword">as</span> pil_image</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    pil_image = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_count_valid_files_in_directory</span><span class="params">(directory, white_list_formats, follow_links)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_recursive_list</span><span class="params">(subpath)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> sorted(os.walk(subpath, followlinks=follow_links), key=<span class="keyword">lambda</span> tpl: tpl[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    samples = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> root, _, files <span class="keyword">in</span> _recursive_list(directory):</span><br><span class="line">        <span class="keyword">for</span> fname <span class="keyword">in</span> files:</span><br><span class="line">            is_valid = <span class="keyword">False</span></span><br><span class="line">            <span class="keyword">for</span> extension <span class="keyword">in</span> white_list_formats:</span><br><span class="line">                <span class="keyword">if</span> fname.lower().endswith(<span class="string">'.'</span> + extension):</span><br><span class="line">                    is_valid = <span class="keyword">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> is_valid:</span><br><span class="line">                samples += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_list_valid_filenames_in_directory</span><span class="params">(directory, white_list_formats,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       class_indices, follow_links)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_recursive_list</span><span class="params">(subpath)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> sorted(os.walk(subpath, followlinks=follow_links), key=<span class="keyword">lambda</span> tpl: tpl[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    classes = []</span><br><span class="line">    filenames = []</span><br><span class="line">    subdir = os.path.basename(directory)</span><br><span class="line">    basedir = os.path.dirname(directory)</span><br><span class="line">    <span class="keyword">for</span> root, _, files <span class="keyword">in</span> _recursive_list(directory):</span><br><span class="line">        <span class="keyword">for</span> fname <span class="keyword">in</span> files:</span><br><span class="line">            is_valid = <span class="keyword">False</span></span><br><span class="line">            <span class="keyword">for</span> extension <span class="keyword">in</span> white_list_formats:</span><br><span class="line">                <span class="keyword">if</span> fname.lower().endswith(<span class="string">'.'</span> + extension):</span><br><span class="line">                    is_valid = <span class="keyword">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">if</span> is_valid:</span><br><span class="line">                classes.append(class_indices[subdir])</span><br><span class="line">                <span class="comment"># add filename relative to directory</span></span><br><span class="line">                absolute_path = os.path.join(root, fname)</span><br><span class="line">                filenames.append(os.path.relpath(absolute_path, basedir))</span><br><span class="line">    <span class="keyword">return</span> classes, filenames</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(pool,apply)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> dirpath <span class="keyword">in</span> (os.path.join(directory, subdir) <span class="keyword">for</span> subdir <span class="keyword">in</span> classes):</span><br><span class="line">        results.append(apply(_list_valid_filenames_in_directory,</span><br><span class="line">                                        (dirpath, white_list_formats,class_indices, <span class="keyword">False</span>)))</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">'__main__'</span>:</span><br><span class="line">    results = []</span><br><span class="line">    directory = <span class="string">'E:\\hxd\\零样本学习\\data\\Atrain\\train\\'</span></span><br><span class="line">    white_list_formats = &#123;<span class="string">'png'</span>, <span class="string">'jpg'</span>, <span class="string">'jpeg'</span>, <span class="string">'bmp'</span>, <span class="string">'ppm'</span>&#125;</span><br><span class="line">    classes = []</span><br><span class="line">    <span class="keyword">for</span> subdir <span class="keyword">in</span> sorted(os.listdir(directory)):</span><br><span class="line">        <span class="keyword">if</span> os.path.isdir(os.path.join(directory, subdir)):</span><br><span class="line">            classes.append(subdir)</span><br><span class="line">    class_indices = dict(zip(classes, range(len(classes))))</span><br><span class="line">    print(<span class="string">'==========IO密集型非阻塞多线程=========='</span>)</span><br><span class="line">    start=time.time()</span><br><span class="line">    pool = multiprocessing.pool.ThreadPool()</span><br><span class="line">    main(pool,pool.apply_async)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    print(<span class="string">'ThreadPool Time:%f'</span>%(time.time()-start))</span><br><span class="line">    print(<span class="string">'==========IO密集型非阻塞多进程=========='</span>)</span><br><span class="line">    results = []</span><br><span class="line">    start=time.time()</span><br><span class="line">    pool = multiprocessing.Pool()</span><br><span class="line">    main(pool,pool.apply_async)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    print(<span class="string">'ProcessPool Time:%f'</span>%(time.time()-start))</span><br><span class="line">    print(<span class="string">'==========IO密集型阻塞多线程=========='</span>)</span><br><span class="line">    start=time.time()</span><br><span class="line">    pool = multiprocessing.pool.ThreadPool()</span><br><span class="line">    main(pool,pool.apply)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    print(<span class="string">'ThreadPool Time:%f'</span>%(time.time()-start))</span><br><span class="line">    print(<span class="string">'==========IO密集型阻塞多进程=========='</span>)</span><br><span class="line">    results = []</span><br><span class="line">    start=time.time()</span><br><span class="line">    pool = multiprocessing.Pool()</span><br><span class="line">    main(pool,pool.apply)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br><span class="line">    print(<span class="string">'ProcessPool Time:%f'</span>%(time.time()-start))</span><br><span class="line">   <span class="string">"""</span></span><br><span class="line"><span class="string">==========IO密集型非阻塞多线程==========</span></span><br><span class="line"><span class="string">ThreadPool Time:1.554570</span></span><br><span class="line"><span class="string">==========IO密集型非阻塞多进程==========</span></span><br><span class="line"><span class="string">ProcessPool Time:1.008292</span></span><br><span class="line"><span class="string">==========IO密集型阻塞多线程==========</span></span><br><span class="line"><span class="string">ThreadPool Time:1.458078</span></span><br><span class="line"><span class="string">==========IO密集型阻塞多进程==========</span></span><br><span class="line"><span class="string">ProcessPool Time:2.155637</span></span><br><span class="line"><span class="string">   """</span></span><br></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>  在实际应用中合理的应用并发多进程和多线程可以提高程序运行效率，针对不同任务类型如IO密集型任务的网络爬虫，CPU密集型的XGBoost的c++实现上均使用了多线程。本文从概念和简单实践出发分别阐述了多进程，多线程，协程等具体操作，以及生产者与消费者，同步与异步和阻塞与非阻塞等相关概念。期望能在将来遇到实际问题时能够有法可循。</p><h2 id="reference">Reference</h2><ol type="1"><li>GIL-维基百科</li><li><p>https://www.cnblogs.com/vipchenwei/p/7809967.html</p></li><li><p>https://blog.csdn.net/SecondLieutenant/article/details/79396984</p></li><li>https://eastlakeside.gitbooks.io/interpy-zh/content/Coroutines/</li><li><p>https://segmentfault.com/a/1190000008909344</p></li></ol>]]></content>
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 多进程 </tag>
            
            <tag> 多线程 </tag>
            
            <tag> 协程 </tag>
            
            <tag> 并行操纵 </tag>
            
            <tag> 同步和异步 </tag>
            
            <tag> 全局解释器锁 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python小工具</title>
      <link href="/2018/08/24/python%E6%89%B9%E9%87%8F%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"/>
      <url>/2018/08/24/python%E6%89%B9%E9%87%8F%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/</url>
      <content type="html"><![CDATA[<p>  记录一些经常用的实用小工具和函数包。会持续更新我实际需求用到的代码，相关当笔记用，方便查阅。</p><ul><li><p>[x] OS 不可描述的强大</p></li><li><p>[x] shutil 复制/移动/修改文件夹操作</p><a id="more"></a></li></ul><h2 id="os">OS</h2><p>os.sep 可以取代操作系统特定的路径分隔符。windows下为 ‘\’</p><p>os.name 字符串指示你正在使用的平台。比如对于Windows，它是’nt’，而对于Linux/Unix用户，它是 ‘posix’</p><p>os.getcwd() 函数得到当前工作目录，即当前Python脚本工作的目录路径</p><p>os.getenv() 获取一个环境变量，如果没有返回none</p><p>os.putenv(key, value) 设置一个环境变量值</p><p>os.listdir(path) 返回指定目录下的所有文件和目录名</p><p>os.remove(path) 函数用来删除一个文件</p><p>os.system(command) 函数用来运行shell命令</p><p>os.linesep 字符串给出当前平台使用的行终止符。例如，Windows使用 ‘’，Linux使用 ‘’ 而Mac使用 ‘’</p><p>os.path.split(path) 函数返回一个路径的目录名和文件名</p><p>os.path.isfile() 和os.path.isdir()函数分别检验给出的路径是一个文件还是目录</p><p>os.path.exists() 函数用来检验给出的路径是否真地存在</p><p>os.curdir 返回当前目录 (‘.’)</p><p>os.mkdir(path) 创建一个目录</p><p>os.makedirs(path) 递归的创建目录</p><p>os.chdir(dirname) 改变工作目录到dirname</p><p>os.path.getsize(name) 获得文件大小，如果name是目录返回0L</p><p>os.path.abspath(name) 获得绝对路径</p><p>os.path.normpath(path) 规范path字符串形式</p><p>os.path.splitext() 分离文件名与扩展名</p><p>os.path.join(path,name) 连接目录与文件名或目录</p><p>os.path.basename(path) 返回文件名</p><p>os.path.dirname(path) 返回文件路径</p><p>os.walk(top,topdown=True,onerror=None) 遍历迭代目录 return 三元组 （路径，文件夹，filename）</p><p>os.rename(src, dst) 重命名file或者directory src到dst 如果dst是一个存在的directory, 将抛出OSError. 在Unix, 如果dst在存且是一个file, 如果用户有权限的话，它将被安静的替换. 操作将会失败在某些Unix 中如果src和dst在不同的文件系统中. 如果成功, 这命名操作将会是一个原子操作 (这是POSIX 需要). 在 Windows上, 如果dst已经存在, 将抛出OSError，即使它是一个文件. 在unix，Windows中有效。</p><p>os.renames(old, new) 递归重命名文件夹或者文件。像rename()</p><h1 id="shutil-模块">shutil 模块</h1><p>shutil.copyfile( src, dst) 从源src复制到dst中去。当然前提是目标地址是具备可写权限。抛出的异常信息为IOException. 如果当前的dst已存在的话就会被覆盖掉</p><p>shutil.move( src, dst) 移动文件或重命名</p><p>shutil.copymode( src, dst) 只是会复制其权限其他的东西是不会被复制的</p><p>shutil.copystat( src, dst) 复制权限、最后访问时间、最后修改时间</p><p>shutil.copy( src, dst) 复制一个文件到一个文件或一个目录</p><p>shutil.copy2( src, dst) 在copy上的基础上再复制文件最后访问时间与修改时间也复制过来了，类似于cp –p的东西</p><p>shutil.copy2( src, dst) 如果两个位置的文件系统是一样的话相当于是rename操作，只是改名；如果是不在相同的文件系统的话就是做move操作</p><p>shutil.copytree( olddir, newdir, True/Flase)把olddir拷贝一份newdir，如果第3个参数是True，则复制目录时将保持文件夹下的符号连接，如果第3个参数是False，则将在复制的目录下生成物理副本来替代符号连接</p><p>shutil.rmtree( src ) 递归删除一个目录以及目录内的所有内容</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""keras需要读取文件夹生成类别，然而很多时候我们只有文件名和类别。需要我们写小爬虫，或者把所有文件分类到不同文件夹</span></span><br><span class="line"><span class="string">#记录示例代码：</span></span><br><span class="line"><span class="string">train.txt : IMAGENAMECLASSNAME</span></span><br><span class="line"><span class="string">train: DIR/IMAGE</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line">f = open(<span class="string">'G:\\零样本识别\\data\Atrain\\train.txt'</span>)</span><br><span class="line">trainfile = f.readlines()</span><br><span class="line">trainID = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> trainfile:</span><br><span class="line">    file = file.rsplit(<span class="string">'\t'</span>)</span><br><span class="line">    trainID[file[<span class="number">0</span>]] = file[<span class="number">1</span>].rsplit(<span class="string">'\n'</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">del</span> trainfile,file</span><br><span class="line">f.close()</span><br><span class="line">trainpath = <span class="string">'G:\\零样本识别\\data\Atrain\\train\\'</span></span><br><span class="line">i=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> trainID.keys():</span><br><span class="line">    i +=<span class="number">1</span></span><br><span class="line">    <span class="keyword">print</span> (i)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(trainpath+trainID[img]):</span><br><span class="line">        os.mkdir(trainpath+trainID[img])</span><br><span class="line">    shutil.move(trainpath+img,trainpath+trainID[img])</span><br></pre></td></tr></table></figure>]]></content>
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 批量文件操作工具 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深入boosting经典算法</title>
      <link href="/2018/08/02/%E6%B7%B1%E5%85%A5boosting%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/"/>
      <url>/2018/08/02/%E6%B7%B1%E5%85%A5boosting%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95/</url>
      <content type="html"><![CDATA[<p> 本文旨在梳理 Boosting方法相关的概念及理论推导。 在介绍Boosting方法之前，我们应该对机器学习模型的误差分析有所了解。从经典的Boosting算法—标准Adaboost的原理入手建立Boosting算法的基本理解，再来分析GBDT的原理(下文的GBDT特指(Greedy Function Approximation：A Gradient  Boosting Machine )提出的算法)及其变体XGBoost和Lightgbm后续文章再讲。</p><a id="more"></a><h2 id="机器学习中的误差偏差与方差">机器学习中的误差，偏差与方差</h2><p>  误差反映的是整个模型的<strong>准确度</strong>，偏差反映的是一个模型在样本上的输出与真实值之间的误差，即模型本身的<strong>精准度</strong>，方差反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的<strong>稳定性/泛化能力</strong>。 偏差和方差的概念粗略的表示为<code>训练误差</code>和<code>|训练误差-测试误差|</code>。偏差过大表现为过拟合，方差过大表现为过拟合。</p><p>  集成方法是将几种机器学习技术组合成一个预测模型的元算法，以达到减小方差(过拟合)（bagging）、偏差（boosting）或改进预测（stacking）的效果。</p><h2 id="boosting算法">Boosting算法</h2><p>  boosting算法是通过多个弱学习器串联提升成为强分类器，通常为加法模型和前向分布算法，核心为下级弱学习器修正上级学习器的偏差。</p><p>  问题：为什么多个弱分类器串联在一起可以提升模型的能力减小偏差而不出现过大方差？ boosting算法要求的基分类器不是没有条件的！首先，基分类器需要一定的的<code>可靠性</code>，其次基分类器需要具有<code>多样性</code>。然而很多情况下<code>可靠性</code>和<code>多样性</code>难以兼得。</p><h3 id="adaboost">Adaboost</h3><p> AdaBoost是<em>Adaptive Boosting</em>缩写，是由Yoav Freund和Robert Schapire提出的机器学习元算法。AdaBoost在某种意义上是适应性的，即随后的弱学习器会基于先前分类器分类错误的样本增加权重。AdaBoost对噪声数据和异常值敏感。在某些问题中，它可能比其他学习算法更不容易受到过拟合问题的影响。基学习器可能很弱，但只要每个学习者的表现好于随机猜测，最终的模型可以融合成表现优异的强分类器。</p><p> Adaboost算法有多种推导方法[1]，比较容易理解的就是基于<code>加性模型(additive model)</code>,即基学习器的线性组合来最小化指数损失函数。 <span class="math display">\[l_{exp}(H|D)=E_{x-D}[e^{-f(x)H(x)}]···········(1)\]</span></p><p><span class="math display">\[H(x) = \sum_{t=1}^{T}\alpha_th_t(x)···········(2) \\ 其中,T表示弱学习器个数，\alpha_t表示第t个学习器的权重，h_t(x)表示第t个学习器的输出\]</span>  Adaboost的核心思想：1. 给错误分类的样本增加权重，让随后的分类器可以有偏的输出；2. 给各个基学习器加上权重。那么怎么给，有什么依据？</p><hr><blockquote><h5 id="adaboost算法描述">Adaboost算法描述：</h5><p> 输入：训练集<span class="math inline">\(D={(x_1,y_1),(x_2,y_2),···,(x_m,y_m)}\)</span>,其中<span class="math inline">\(y_i\in [-1,1]\)</span></p><p> 基学习器f；</p><p> 迭代次数T；</p><p> (1) 初始化样本权重<span class="math inline">\(W_1(x)=\frac{1}{m}\)</span></p><p> (2)迭代T次(for)，算出每个模型的误差<span class="math inline">\(e_t = \sum_{i=1}^{M}I(y_i\ne h_t(x_i))\)</span></p><p> (3)if <span class="math inline">\(\epsilon &gt;0.5\)</span>then break</p><p> (4)更新<span class="math inline">\(\alpha_t=\frac{1}{2}ln(\frac{1-e_t}{e_t})\)</span></p><p> (5)更新样本新权重<span class="math inline">\(W_t(x)=\frac{W_{t-1}exp(-\alpha_{t-1}h_{t-1}y_i)}{Z_{t-1}},其中Z_{t-1}=\sum_{}^{}W_{t-1}\)</span></p><p> 输出：<span class="math inline">\(H(x)=sign(\sum_{t=1}^{T}\alpha_th_t(x))\)</span></p><hr></blockquote><p>问题：显然按照这个算法流程，标准的adaboost实现的是二分类，那么多分类，回归任务需要改进。这仅仅是adaboost的一个应用。</p><p>adaboost理论推导的俩个核心：在界定了错误率<span class="math inline">\(\epsilon_t\)</span>的情况下,求解或者估计<span class="math inline">\(\alpha_t\)</span>和新的分布<span class="math inline">\(W_t\)</span>使指数损失函数最小。</p><ol type="1"><li><span class="math inline">\(\alpha_t\)</span>的求解</li></ol><p><span class="math display">\[l_{exp}(H|W)=E_{x-W}[e^{-f(x)H(x)}]=p_{x-W}(f(x)=h_t(x))e^{-\alpha_t}+p_{x-W}(f(x)\ne h_t(x))e^{\alpha_t}=e^{-\alpha_t}(1-\epsilon_t)+e^{\alpha_t}\epsilon_t\]</span></p><p><span class="math display">\[\frac{\nabla \ell_{exp}(H|W)}{\nabla\alpha_t}=-e^{-\alpha_t}(1-\epsilon_t)+e^\alpha_t\epsilon_t\]</span></p><p>令<span class="math inline">\(\frac{\nabla l_{exp}(H|D)}{\nabla\alpha_t}=0\)</span>可解得： <span class="math display">\[\alpha_t=\frac{1}{2}ln\frac{1-\epsilon_t}{\epsilon_t}\]</span></p><ol start="2" type="1"><li><span class="math inline">\(W_t\)</span>的求解</li></ol><p> Adaboost的算法核心是在上一个学习器的基础上，对错误分类的样本权重进行向上调整，使其在后面的学习中更被关注。这个地方我们就要说到模型的多样性的重要了。某个样本在一些弱分类器上的表现不好，就在其他分类器上还可能获得增强，然后加性融合时其可获得较低的偏差。然是如果他在所有弱分类器上的表现都不好，那么加性模型也难以修正其偏差，多样性是boost算法一个需要的重要的属性。</p><p> 在基分类器<span class="math inline">\(h_t(x)\)</span>时的模型损失函数表达为： <span class="math display">\[\ell_{exp}(H_{t-1}+h_t(x)|W_t)=E_{x-W}[e^{-f(x)(H_{t-1}(x)+h_t(x))}]=E_{x-W}[e^{-f(x)H_{t-1}(x)}e^{-f(x)h_t(x))}]\]</span> 对二分类，将<span class="math inline">\(e^{-f(x)h_t(x)}\)</span>的二阶泰勒展开带入损失函数近似可得： <span class="math display">\[\ell_{exp}(H_{t-1}+h_t{x}|W)=E_{x-W}[e^{-f(x)H_{t-1}(x)}(\frac{3}{2}-f(x)h_t(x))]\]</span> 最理想情况在当前模型(<span class="math inline">\(H_{t}(x)\)</span>)的损失函数最小(即<span class="math inline">\(h_t(x)\)</span>纠正了<span class="math inline">\(H_{t-1}(x)\)</span>)的条件下求解<span class="math inline">\(W_t\)</span>。</p><p>即： <span class="math display">\[h_t(x)=\arg\min_{h}\ell_{exp}(H_{t-1}(x)+h_t(x)|W) = \arg\min_{h}E_{x-W}[e^{-f(x)H_{t-1}(x)}(\frac{3}{2}-f(x)h_t(x))]\\= \arg\max_{h}E_{x-W}[e^{-f(x)H_{t-1}(x)}f(x)h_t(x)]\]</span> <span class="math inline">\(f(x)和H_{t-1}(x)\)</span>已知。令： <span class="math display">\[W_t=\frac{W(x)e^{-f(x)H_{t-1}(x)}}{E_{x-W}[e^{-f(x)H_{t-1}(x)}]}\]</span> <span class="math display">\[理想的基分类器：h_t(x)=\arg\max_{h}E_{x-W}[W_tf(x)h_t(x)]=\arg\min_{h}E_{x-W_t}[I(f(x) \ne h_t(x))]\]</span></p><p><span class="math inline">\(h_t(x)\)</span>在分布<span class="math inline">\(W_t\)</span>下仍然可以达到最小分类误差。</p><h3 id="gdbt">GDBT</h3><p><strong><em>吐槽：GDBT真的是太难理解了！如果只从概念上知道GDBT用不断的加基模型减小残差，那可能并没有完全理解GDBT</em></strong>。<strong><em>GDBT模型怎么加的？怎么分类的？输入是多维的构建树的过程是什么样的</em></strong>？</p><p>GDBT的基分类器是CART回归树，GDBT是通过不断地最小化残差来实现加法模型，其中梯度提升的本质是每一次建立模型是在之前建立模型损失函数的梯度下降方向 。梯度提升树在结构化数据上的具有优越性，如推荐系统和计算广告里面。</p><p> GDBT在处理回归问题时的残差其实就在最小平方损失函数的负梯度方向，即： <span class="math display">\[r_{mi}=-\frac{\partial[\frac{1}{2}(y_i-f_m(x_i))^2]}{\partial f_m(x_i)}=y_i-f_m(x_i)\]</span>  常见的损失函数即负梯度方向：</p><figure><img src="/images/GDBT损失函数.png" alt="GDBT常见损失函数"><figcaption>GDBT常见损失函数</figcaption></figure><p> 上面的叙述说明，残差是负梯度方向的一个例子，GDBT将梯度下降法的优化概理念从参数空间的优化扩展到函数空间的优化。熟悉神经网络的同学应该知道，标准的神经网络是在一个模型上迭代的更新参数<span class="math inline">\(\theta^{*}\)</span>以达到损失函数最小的期望；在GDBT算法中拓展到函数空间是如何优化的呢？</p><p> 浓缩一下：一个变，一个不变！</p><ul><li><p>一个变：基CART回归树的拟合目标<span class="math inline">\(y^*\)</span>是在变的，它是上个CART回归树的负梯度(残差)。</p></li><li><p>一个不变： 每个样本的ground truth是不变的。</p></li></ul><blockquote><hr><p><strong>GDBT算法</strong>：</p><p> 输入：<span class="math inline">\((x_i,y_i)_{i=1}^{i=N}\)</span>，迭代次数M，损失函数$$</p><p> 输出：<span class="math inline">\(F(x)=\sum_{j=1}^{j=M}f_j(x)\)</span></p><p> 1. 学习第一棵树得到残差： <span class="math display">\[r_{mi}=-\left[\frac{\partial L\left(y,f\left(x_i\right)\right)}{\partial f\left(x_i\right)}\right]_{f\left(x\right)=f_{m-1}\left(x\right)}\]</span>   注：初始化第一棵树的负梯度方向（后面的要拟合的<span class="math inline">\(y_i\)</span>）</p><p> 2. for m =2:M do:</p><p>  2.1 拟合上一棵树棵树的残差，计算输出响应<span class="math inline">\(y_{mi}\)</span>:<span class="math inline">\(y_{i}=[\frac {\partial \ell(y_i,F(x_{i}))}{\partial {F(x_{i})}}]_{F_(x)=F_{m-1}(x)}\)</span></p><p>  2.2 学习第m棵树： <span class="math inline">\(\gamma^*=\arg\min_{w} \sum_{x_i \in R_m}^{}\ell (y_i,F_{m-1}(x_i)+\gamma)\)</span>,即利用线性搜索(line search)估计叶结点区域的值，使损失函数极小化 。</p><p>  2.3 更新树： <span class="math display">\[F_m\left(x\right)=F_{m-1}\left(x\right)+\sum_{j=1}^{J}{\gamma{mj}I\left(x\in R_{mj}\right)},其中J是叶节点\]</span>  3. 训练结束，输出： <span class="math display">\[\hat{F}\left(x\right)=F_M\left(x\right)=\sum_{m=1}^M{\sum_{j=1}^J{\gamma_{mj}I\left(x\in R_{mj}\right)}}\]</span> ——</p></blockquote><h2 id="参考">参考：</h2><ol type="1"><li>周志华,《机器学习》</li><li>jerome H.Friedman,Greedy Function Approximation：A Gradient  Boosting Machine</li><li>陈天奇，<a href="http://www.52cs.org/?p=429" target="_blank" rel="noopener">XGBoost 与 Boosted Tree</a></li></ol>]]></content>
      
      <categories>
          
          <category> 机器学习算法 </category>
          
          <category> 集成方法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GDBT </tag>
            
            <tag> Adaboost </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>浅析决策树</title>
      <link href="/2018/07/28/%E6%B5%85%E6%9E%90%E5%86%B3%E7%AD%96%E6%A0%91/"/>
      <url>/2018/07/28/%E6%B5%85%E6%9E%90%E5%86%B3%E7%AD%96%E6%A0%91/</url>
      <content type="html"><![CDATA[<h3 id="前言">前言：</h3><p> 决策树归纳是从有类标号的训练元组中学习决策模型。常用的决策树算法有ID3，C4.5和CART。它们是采用贪心（即非回溯的）方法，自顶向下递归的分治方法构造。这几个算法选择属性划分的方法各不相同，ID3使用的是信息增益，C4.5使用的是信息增益率，而CART使用的是Gini基尼指数。下面来简单介绍下决策树的理论知识。内容包含<strong>决策树的算法构成</strong>，<strong>熵</strong>、<strong>信息增益</strong>、<strong>信息增益率</strong>以及<strong>Gini指数</strong>和<strong>树的剪枝</strong>的概念及公式。</p><a id="more"></a><h4 id="快速系统的理解一个机器学习算法">快速系统的理解一个机器学习算法</h4><ol type="1"><li>算法要解决的问题什么?</li><li>算法的输入输出是什么?</li><li>算法的实现的机理是什么?</li><li>算法的优化方法是什么？</li><li>算法的评价指标是什么？</li></ol><h3 id="决策树的算法构成">决策树的算法构成</h3><p> 决策树归纳是从有类标号的训练元组中学习决策模型。常用的决策树算法有ID3，C4.5和CART。它们都是采用贪心（即非回溯的）方法，自顶向下递归的分治方法构造。这几个算法选择属性划分的方法各不相同，ID3使用的是信息增益，C4.5使用的是信息增益率，而CART使用的是Gini基尼指数。下面来简单介绍下决策树的理论知识。内容包含<strong>决策树的算法构成</strong>，<strong>熵</strong>、<strong>信息增益</strong>、<strong>信息增益率</strong>以及<strong>Gini指数</strong>和<strong>树的剪枝</strong>的概念及公式。</p><p>​ 决策树是是由特征空间作为结点和类空间作为叶子构建的一棵树。：</p><h4 id="特征划分逻辑">特征划分逻辑</h4><p>  以每个特征作为判别标志（根节点），用if…then…作为分裂规则(yes or no)，将特征空间划分成互斥且完备的子空间，通过不断地划分子空间，树不断地生长。具体的划分依据和逻辑见第三章。 <img src="/images/决策树示意图.jpg" alt="决策树示意图"></p><h4 id="分类规则">分类规则：</h4><p> 从统计的角度出发，节点对应的最大条件概率作为分类准则。(要明白似然函数和概率的区别)</p><h4 id="优化">优化：</h4><p>  决策树的损失函数通常是正则化的极大似然函数，学习的策略是以损失函数为目标函数的最小化。决策树采用<strong>启发式算法</strong>来近似求解最优化问题，得到的是次最优的结果。</p><p>​ 该启发式算法可分为三步：</p><ul><li>特征选择</li><li>模型生成</li><li>决策树的剪枝</li></ul><h3 id="决策树生成与剪枝">决策树生成与剪枝</h3><h4 id="信息量与熵">信息量与熵</h4><p> 不管是分类任务还是回归任务，都是在做这样一件事情<strong>传递消息（类别or回归值）</strong>；特征就是我们对需要传递的消息的一种编码方式即信息。那么怎么衡量信息?信息论定义如下： <span class="math display">\[信息量：l(x_i)=-log_2p(x_i)\]</span> ​ 有了信息（特征）以后怎么确定这个信息是否可靠的表达消息？我们定义熵来度量信息是否可靠。 <span class="math display">\[熵：H(x) = -\sum_{i=1}^np_ilog(p_i)\\]</span></p><p><span class="math display">\[条件熵： H(Y|X) = H(X,Y)-H(X) = \sum_XP(X)H(Y|X) = -\sum_{X,Y}logP(Y|X)\]</span></p><p> <strong>熵越大，说明系统越混乱，携带的信息就越少。熵越小，说明系统越有序，携带的信息就越多</strong>。信息的作用就是在于消除不确定性。 均匀分布的不确定性最大，即特征均匀分布（所有特征都一样）熵最大，特征完全没有区分性，无法准确传递消息（类别or回归）。条件熵<code>H（Y|X）</code>描述的是在X给定的条件下Y的不确定性，如果条件熵越小，表示不确定性就越小，那么B就越容易确定结果。</p><h4 id="id3算法与信息增益">ID3算法与信息增益</h4><p> ID3划分特征（创建节点的规则）使用的就是信息增益<code>Info-Gain</code>排序。<strong>一个特征的信息增益越大，表明该对样本的熵减少的能力就更强，该特征使得数据所属类别的不确定性降低</strong>。信息增益描述特征对分类(回归)的不确定性的降低程度，可以用来度量两个变量的相关性。比如，在给定一个变量的条件下，另一个变量它的不确定性能够降低多少，如果不确定性降低得越多，那么它的确定性就越大，就越容易区分，两者就越相关。</p><ol type="1"><li><p><code>信息增益</code></p> 信息增益在统计学中称为互信息，互信息是条件概率与后验概率的比值，化简之后就可以得到信息增益。所以说互信息其实就是信息增益。计算方法: <span class="math display">\[G(D, A) = H(D) - H(D|A) ，H(D)经验熵，H(D|A)经验条件熵，D表示训练集，A表示特征空间\]</span> <span class="math display">\[H(D)=-\sum_{k=1}^K\frac{|C_k|}{|D|}log\frac{|C_k|}{|D|}，其中，|C_k|是属于类C_k的个数，|D|是所有样本的个数\]</span> <span class="math display">\[H(D|A)=\sum_{i=1}^np_{a_i}H(D|a_i)=\sum_{i=1}^n\frac{|D_i|}{|D|}H(D_i)=-\sum_{i=1}^n\frac{|D_i|}{|D|}\sum_{k=1}^{K}\frac{|D_{ik}|}{|D_i|}log\frac{|D_{ik}|}{|D_i|}，\\特征A有个不同的划分取值\{a_1, a_2, ..., a_n\}，根据特征A的划分取值将D划分为n个子集D_1, D_2, ..., D_n， |D_i|是D_i的样\\本个数，D_ik是中属于C_k类的样本集合。\]</span></li><li><p><code>ID3算法流程图</code> 对非空非单一特征空间<code>A</code>: <img src="/images/ID3.jpg" alt="id3算法流程"></p></li></ol><h4 id="c4.5算法与信息增益比">C4.5算法与信息增益比</h4><p> C4.5算法用<code>信息增益比</code>作为特征选择的依据。算法流程与ID3类似。 使用信息增益作为特征选择的标准时，容易偏向于那些取值比较多的特征，容易导致过拟合。而采用信息增益比则有效地抑制了这个缺点：取值多的特征，以它作为根节点的单节点树的熵很大，导致信息增益比减小，在特征选择上会更加合理。 <span class="math display">\[信息增益比: g_R(D,A)=\frac{g(D,A)}{H_A(D)}, 其中   H_A(D) = -\sum_{i=1}^n\frac{D_i}{D}log_2\frac{D_i}{D}，n为特征A取值的个数\]</span>  我的理解就是信息增益比在信息增益上做了个平滑处理，将特征对应的信息增益与特征空间划分的熵相结合起来，约束了不同取值特征的信息增益处理不均衡的问题，在一定程度生类似于标准化，正向统一特征划分的标准。</p><h4 id="cart算法">CART算法</h4><p> CART(分类回归树)算法是由以特征为节点的多个二叉树串联形成可以完成回归任务和分类任务。CART算法同样由特征选择，树的生成及剪枝组成 ；其中回归树用最小平方误差准则，分类树用基尼指数(Gini index)最小化 准则，进行特征选择，生成二叉树。</p><h5 id="最小二乘回归树生成算法">1. 最小二乘回归树生成算法</h5><p> 带着问题看算法： 要搞明白最小二乘法是怎么进行特征选择的？  采用启发式的方法，选择第j个特征和它的取值s作为切分变量和切分点，然后以该特征及切分情况(对应分割区域的输出与真实输出的平方误差和)遍历j的所有取值找到最优的切分点s。具体的优化公式如下： <span class="math display">\[\underset{j,s}{min}[\underset{c_1}{min}\sum_{x_i\in R_1(j,s)}(y_i-c_1)^2+\underset{c_2}{min}\sum_{x_i\in R_2(j,s)}(y_i-c_2)^2]\\其中，R_1(j,s)=\{x|x^{(j)}≤s\},R_2(j,s)=\{x|x^{(j)}＞s\}，c_1={1\over N_1}\sum_{x_i \in R_1}y_i , \quad c_2={1\over N_2}\sum_{x_i \in R_2}y_i\]</span>  统计学习方法上说 对上述俩个子空间递归调用该步骤,直到满足停止条件。 然后将输入空间划分为M个子区域，生成决策树： <span class="math display">\[f(x) = \sum_{m=1}^Mc_mI(x \in R_m)\]</span></p><h5 id="cart分类算法与基尼系数">2. CART分类算法与基尼系数</h5><ol type="1"><li>基尼指数</li></ol><p><span class="math display">\[基尼指数 ：Gini(D) =1-\sum_{k=1}^{K}(\frac{|C_k|}{|D|})^2，其中C_k是D中属于第k类的子集。\\如果样本集合D根据特征A是否取某一可能值a被分割成D1和D2两部分，即\\ D_1=\{(x,y) \in D| A(x) =a\},D_2 = D-D_1\\则在特征A的条件下，集合D的基尼指数定义为 :Gini(D,A) = \frac{\vert D_1\vert}{\vert D\vert}Gini(D_1)+\frac{\vert D_2\vert}{\vert D\vert}Gini(D_2)\]</span> <strong>问题： 那为什么用基尼指数选择特征而不用信息增益或者信息增益率？</strong>​</p><ol start="2" type="1"><li>分类CART生成：</li></ol><hr><p> 输入：训练数据集D，停止计算的条件；</p><p> 输出：CART决策树；</p><p> 根据训练数据集，从根节点开始，递归地对每个结点进行以下操作，构建二叉决策树：</p><p> （1）设结点的训练数据集为D，计算现有特征对该数据集的基尼指数。此时对每一个特征A，对其可能取的每个值a，根据样本点对A=a的测试为“是”或“否”将D分割成D1和D2两部分，利用基尼指数计算公式计算。</p><p> （2）在所有可能的特征A以及它们所有可能的切分点a中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点。依最优特征与最优切分点，从现结点生成两个子结点，将训练数据集依特征分配到两个子结点中去。</p><p> （3）对两个子结点递归地调用（1），（2），直至满足停止条件。</p><p> （4）生成CART决策树</p><p> 算法停止计算的条件是结点中的样本个数小于预定阈值，或样本集的基尼指数小于预定阈值，或者没有更多特征。</p><hr><h4 id="决策树的剪枝">决策树的剪枝</h4><p> 因为决策树的生成算法容易构建过于复杂的决策树，产生过拟合。而剪枝从已生成的树上裁掉一些子树或叶结点，并将其根结点或父结点作为新的叶结点，从而简化分类树模型，在这里我们可以联想其实剪枝就是一直正则化手段，简化模型，防止过拟合！下面我们进行详细介绍：</p><p> 决策树剪枝的基本策略： - 预剪枝(prepruning) 在决策树生成过程中，对每个节点在分割前先进行估计。若当前的分割不能带来决策树泛化性能的提升，则停止分割并将当前节点标记为叶节点 在预剪枝过程中，决策树的很多分支都没有展开，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间和预测时间；但有些分支的当前分割虽不能提升泛化性能、甚至能导致泛化性能下降，但在其基础上的后续分割却有可能导致泛化性能的显著提高，容易导致欠拟合 - 后剪枝(postpurning) 先从训练样本集生成一棵最大规模的完整的决策树，然后自底向上地对非叶结点进行考察。若将该提升决策树的泛化性能，则将该子树替换为叶节点节点对应的子树替换为叶节点能 后剪枝决策树比预剪枝决策树保留了更多的分支。后剪枝过程的欠拟合风险很小，泛化性能往往优于预剪枝决策树，但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中所有的非叶节点进行逐一考察，因此训练时间开销比未剪枝决策树和预剪枝决策树都要大的多</p><ol type="1"><li><p><strong>决策树的剪枝</strong></p><p> 决策树的剪枝往往通过极小化决策树整体的损失函数或代价函数来实现。 设树T的叶结点个数为<span class="math inline">\(|T|\)</span>，t是树T的叶结点，该叶结点有<span class="math inline">\(N_t\)</span>个样本结点，其中k类的样本点有<span class="math inline">\(N_{tk}\)</span>，k = 1, 2, …, K，<span class="math inline">\(H_t(T)\)</span>为叶结点t上的经验熵，α≥0为参数，则决策树学习的损失函数可以定义为 :<span class="math inline">\(C_{\alpha}(T_t) = C(T_t) + \alpha|T_t|\)</span> 其中经验熵:<span class="math inline">\(H_t(T)=-\sum_{i}^{K}\frac{|N_{ik}|}{N_i}log\frac{|N_{ik}|}{N_i}\)</span> 在损失函数中，将第1项记作:<span class="math inline">\(C(T)=\sum_{t=1}^{|T|}N_tH_t(T)=\sum_{t=1}^{|T|}\sum_{k=1}^{K}N_{tk}log\frac{N_{tk}}{N_t}\)</span> 则：<span class="math inline">\(C_\alpha(T)=C(T)+\alpha|T|\)</span></p><p> C(T)表示模型对训练数据的预测误差，即模型与训练数据的拟合程度，<span class="math inline">\(|T|\)</span>表示模型的复杂度，参数<span class="math inline">\(\alpha\)</span>控制两者之间的影响。较大的<span class="math inline">\(\alpha\)</span>促使选择较简单的模型（树），较小的<span class="math inline">\(\alpha\)</span>促使选择较复杂的模型（树）。<span class="math inline">\(\alpha=0\)</span>意味着只考虑模型与训练数据的拟合程度，不考虑模型的复杂度。 剪枝，就是当α确定时，选择损失函数最小的模型（树）。但α值确定时，子树越大，往往与训练数据的拟合越好，但是模型的复杂度就越高；相反，子树越小，模型的复杂度就越低，但是往往与训练数据的拟合不好。损失函数正好表示了对两者的平衡。 可以看出，决策树生成只考虑了通过提高信息增益（或信息增益比）对训练数据进行更好的拟合。而决策树剪枝通过优化损失函数还考虑了减小模型复杂度。<strong>决策树生成学习局部的模型，而决策树剪枝学习整体的模型</strong>。 <strong>损失函数的极小化等价于正则化的极大似然估计</strong>。所以，利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择。</p><hr><p>决策树剪枝算法：</p><p>输入：生成算法产生的整个树T，参数<span class="math inline">\(\alpha\)</span>;</p><p>输出：修剪后的子树<span class="math inline">\(T_\alpha\)</span></p><p>（1）计算每个结点的经验熵；</p><p>（2）递归地从树的叶结点向上回缩。设一组叶结点回缩到其父结点之前与之后的整体树分别为<span class="math inline">\(T_B\)</span>和<span class="math inline">\(T_A\)</span>，其对应的损失函数值分别是<span class="math inline">\(C_\alpha(B)\)</span>和<span class="math inline">\(C_\alpha(A)\)</span>，如果<span class="math inline">\(C_\alpha(B)\le C_\alpha(A)\)</span> 则进行剪枝，即父结点变为新的叶结点。</p><p>（3）返回（2），直至不能继续为止，得到损失函数最小的子树<span class="math inline">\(T_\alpha\)</span>。</p><hr></li><li><p><strong>CART剪枝</strong></p><p> 相比一般剪枝算法，CART剪枝算法的优势在于，<strong>不用提前确定α值</strong>，而是在剪枝后从所有子树中找到最优子树对应的<span class="math inline">\(\alpha\)</span>值。 对于固定的α值，一定存在让<span class="math inline">\(C_\alpha(T)\)</span>最小的唯一的子树，记<span class="math inline">\(T_\alpha\)</span>。 <img src="/images/CART剪枝算法流程.png" alt="CART剪枝算法流程"></p></li></ol><h3 id="决策树小结">决策树小结</h3><h4 id="决策树算法对比">决策树算法对比</h4><table><thead><tr class="header"><th>算法</th><th>支持模型</th><th>树结构</th><th>特征选择</th><th>连续值处理</th><th>缺失值处理</th><th>剪枝</th></tr></thead><tbody><tr class="odd"><td>ID3</td><td>分类</td><td>多叉树</td><td>信息增益</td><td>不支持</td><td>不支持</td><td>不支持</td></tr><tr class="even"><td>C4.5</td><td>分类</td><td>多叉树</td><td>信息增益比</td><td>支持</td><td>支持</td><td>支持</td></tr><tr class="odd"><td>CART</td><td>分类，回归</td><td>二叉树</td><td>基尼系数，均方差</td><td>支持</td><td>支持</td><td>支持</td></tr></tbody></table><h4 id="决策树算法的优缺点">决策树算法的优缺点</h4><ul><li>优点：</li></ul><ol type="1"><li>决策树由明确的规则生成，可解释性强。</li><li>基本不需要预处理，不需要提前归一化，处理缺失值。</li><li>既可以处理离散值也可以处理连续值。</li><li>非参数模型，树模型在不同分布数据上表现更稳定。</li><li>可以交叉验证的剪枝来选择模型，从而提高泛化能力。(验证集(CART)也可以发挥调整模型的作用而不仅仅是评估模型)</li></ol><ul><li>缺点：</li></ul><ol type="1"><li>决策树算法非常容易过拟合，导致泛化能力不强。</li><li>如果某些特征的样本比例过大，生成决策树容易偏向于这些特征。</li></ol><h3 id="参考">参考：</h3><ol type="1"><li>李航. 统计学习方法</li><li><a href="http://www.csuldw.com/2015/05/08/2015-05-08-decision%20tree/" target="_blank" rel="noopener">http://www.csuldw.com/2015/05/08/2015-05-08-decision%20tree/</a></li><li><a href="https://applenob.github.io/decision_tree.html" class="uri" target="_blank" rel="noopener">https://applenob.github.io/decision_tree.html</a></li><li><a href="https://zealscott.com/posts/54670/" class="uri" target="_blank" rel="noopener">https://zealscott.com/posts/54670/</a></li></ol>]]></content>
      
      <categories>
          
          <category> 机器学习算法 </category>
          
          <category> 树模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 决策树 </tag>
            
            <tag> CART </tag>
            
            <tag> ID3 </tag>
            
            <tag> C4.5 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python常用的内置函数</title>
      <link href="/2018/07/27/python%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/"/>
      <url>/2018/07/27/python%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0/</url>
      <content type="html"><![CDATA[<p>  熟悉和掌握python的内置函数，可以在写算法的时候简化代码。</p><a id="more"></a><h2 id="关键字">关键字</h2><p><strong>lambda表达式 :不定义函数名，使用一次的函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">4</span>, <span class="number">1</span>), (<span class="number">9</span>, <span class="number">10</span>), (<span class="number">13</span>, <span class="number">-3</span>)]<span class="comment">#type :list</span></span><br><span class="line">a.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])<span class="comment">#key的用法很高端，规则排序</span></span><br><span class="line">print(a)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[(<span class="number">13</span>, <span class="number">-3</span>), (<span class="number">4</span>, <span class="number">1</span>), (<span class="number">1</span>, <span class="number">2</span>), (<span class="number">9</span>, <span class="number">10</span>)]</span><br></pre></td></tr></table></figure><p><strong>yield函数:可构建生成器，对可迭代对象进行逐次返回，节约计算资源，如keras的 imagegenerator</strong></p><pre><code>1. 可迭代对象`iterable`是实现了`__iter__()`方法的对象，`iter()`方法返回`iterator`对象，通过`next`显示的获取元素,用完一个删一个，当迭代器为空时会抛出异常（StopIteration）（和c++迭代器 （`pop_front`+`iterator++`）理解类似），调用迭代器`for item in iterator:`。</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如list是一个可迭代对象包含__iter__()方法，使用iter(list)变成迭代器iterator</span></span><br><span class="line">&gt;&gt;&gt;dir(list)</span><br><span class="line">[<span class="string">'__add__'</span>, <span class="string">'__class__'</span>, <span class="string">'__contains__'</span>, <span class="string">'__delattr__'</span>, <span class="string">'__delitem__'</span>, <span class="string">'__dir__'</span>, <span class="string">'__doc__'</span>, <span class="string">'__eq__'</span>, <span class="string">'__format__'</span>, <span class="string">'__ge__'</span>, <span class="string">'__getattribute__'</span>, <span class="string">'__getitem__'</span>, <span class="string">'__gt__'</span>, <span class="string">'__hash__'</span>, <span class="string">'__iadd__'</span>, <span class="string">'__imul__'</span>, <span class="string">'__init__'</span>, <span class="string">'__init_subclass__'</span>, <span class="string">'__iter__'</span>, <span class="string">'__le__'</span>, <span class="string">'__len__'</span>, <span class="string">'__lt__'</span>, <span class="string">'__mul__'</span>, <span class="string">'__ne__'</span>, <span class="string">'__new__'</span>, <span class="string">'__reduce__'</span>, <span class="string">'__reduce_ex__'</span>, <span class="string">'__repr__'</span>, <span class="string">'__reversed__'</span>, <span class="string">'__rmul__'</span>, <span class="string">'__setattr__'</span>, <span class="string">'__setitem__'</span>, <span class="string">'__sizeof__'</span>, <span class="string">'__str__'</span>, <span class="string">'__subclasshook__'</span>, <span class="string">'append'</span>, <span class="string">'clear'</span>, <span class="string">'copy'</span>, <span class="string">'count'</span>, <span class="string">'extend'</span>, <span class="string">'index'</span>, <span class="string">'insert'</span>, <span class="string">'pop'</span>, <span class="string">'remove'</span>, <span class="string">'reverse'</span>, <span class="string">'sort'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(a)</span><br><span class="line">list</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>type(iter(a))</span><br><span class="line">list_iterator</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = iter(a)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(b)</span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(b)</span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="comment">#调用迭代器for item in iterator:...</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> item <span class="keyword">in</span> b:</span><br><span class="line">    <span class="keyword">print</span> (item)</span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure><ol start="2" type="1"><li><p>生成器<code>generator</code>就是带<code>yield</code>的函数，<code>generator</code>就是一种迭代器。<code>yield</code>相当于在迭代器迭代的时候加了个断点返回元素不终止执行，遇到下一个next()触发一次执行。</p></li><li><blockquote><p>总结：</p></blockquote><figure><img src="/images/iterators-generators-iterables.png" alt="生成器迭代器关系图"><figcaption>生成器迭代器关系图</figcaption></figure><ul><li>可迭代对象(Iterable)是实现了<code>__iter__()</code>方法的对象,通过调用<code>iter()</code>方法可以获得一个迭代器(Iterator)</li><li>迭代器(Iterator)是实现了<code>__iter__()</code>和<code>__next__()</code>的对象</li><li><code>for ... in ...</code>的迭代,实际是将可迭代对象转换成迭代器,再重复调用<code>next()</code>方法实现的</li><li>生成器(generator)是一个特殊的迭代器,它的实现更简单优雅.</li><li><code>yield</code>是生成器实现<code>__next__()</code>方法的关键.它作为生成器执行的暂停恢复点,可以对<code>yield</code>表达式进行赋值,也可以将<code>yield</code>表达式的值返回.</li></ul></li></ol><h2 id="类型转换">类型转换</h2><p><strong>tuple：根据传入的参数创建一个新的元组</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple() <span class="comment">#不传入参数，创建空元组</span></span><br><span class="line">()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple(<span class="string">'121'</span>) <span class="comment">#传入可迭代对象。使用其元素创建新的元组</span></span><br><span class="line">(<span class="string">'1'</span>, <span class="string">'2'</span>, <span class="string">'1'</span>)</span><br></pre></td></tr></table></figure><p><strong>list：根据传入的参数创建一个新的列表</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;list() <span class="comment"># 不传入参数，创建空列表</span></span><br><span class="line">[] </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(<span class="string">'abcd'</span>) <span class="comment"># 传入可迭代对象，使用其元素创建新的列表</span></span><br><span class="line">[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>]</span><br></pre></td></tr></table></figure><p><strong>dict：根据传入的参数创建一个新的字典</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict() <span class="comment"># 不传入任何参数时，返回空字典。</span></span><br><span class="line">&#123;&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict(a = <span class="number">1</span>,b = <span class="number">2</span>) <span class="comment">#  可以传入键值对创建字典。</span></span><br><span class="line">&#123;<span class="string">'b'</span>: <span class="number">2</span>, <span class="string">'a'</span>: <span class="number">1</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict(zip([<span class="string">'a'</span>,<span class="string">'b'</span>],[<span class="number">1</span>,<span class="number">2</span>])) <span class="comment"># 可以传入映射函数创建字典。</span></span><br><span class="line">&#123;<span class="string">'b'</span>: <span class="number">2</span>, <span class="string">'a'</span>: <span class="number">1</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dict(((<span class="string">'a'</span>,<span class="number">1</span>),(<span class="string">'b'</span>,<span class="number">2</span>))) <span class="comment"># 可以传入可迭代对象创建字典。</span></span><br><span class="line">&#123;<span class="string">'b'</span>: <span class="number">2</span>, <span class="string">'a'</span>: <span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure><p><strong>enumerate：根据可迭代对象创建枚举对象</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>seasons = [<span class="string">'Spring'</span>, <span class="string">'Summer'</span>, <span class="string">'Fall'</span>, <span class="string">'Winter'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(enumerate(seasons))</span><br><span class="line">[(<span class="number">0</span>, <span class="string">'Spring'</span>), (<span class="number">1</span>, <span class="string">'Summer'</span>), (<span class="number">2</span>, <span class="string">'Fall'</span>), (<span class="number">3</span>, <span class="string">'Winter'</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(enumerate(seasons, start=<span class="number">1</span>)) <span class="comment">#指定起始值</span></span><br><span class="line">(range(<span class="number">0</span>, <span class="number">10</span>), range(<span class="number">1</span>, <span class="number">10</span>), range(<span class="number">1</span>, <span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">(range(<span class="number">0</span>, <span class="number">10</span>), range(<span class="number">1</span>, <span class="number">10</span>), range(<span class="number">1</span>, <span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">[(<span class="number">1</span>, <span class="string">'Spring'</span>), (<span class="number">2</span>, <span class="string">'Summer'</span>), (<span class="number">3</span>, <span class="string">'Fall'</span>), (<span class="number">4</span>, <span class="string">'Winter'</span>)]</span><br></pre></td></tr></table></figure><p><strong>range：根据传入的参数创建一个新的range对象</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = range(<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = range(<span class="number">1</span>,<span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = range(<span class="number">1</span>,<span class="number">10</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a,b,c <span class="comment"># 分别输出a,b,c</span></span><br><span class="line">(range(<span class="number">0</span>, <span class="number">10</span>), range(<span class="number">1</span>, <span class="number">10</span>), range(<span class="number">1</span>, <span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(a),list(b),list(c) <span class="comment"># 分别输出a,b,c的元素</span></span><br><span class="line">([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>], [<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>])</span><br></pre></td></tr></table></figure><p><strong>iter：根据传入的参数创建一个新的可迭代对象</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = iter(<span class="string">'abcd'</span>) <span class="comment">#字符串序列</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">&lt;str_iterator object at <span class="number">0x03FB4FB0</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line"><span class="string">'a'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line"><span class="string">'b'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line"><span class="string">'c'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line"><span class="string">'d'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;pyshell#29&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    next(a)</span><br><span class="line">StopIteration</span><br></pre></td></tr></table></figure><h2 id="序列操作">序列操作</h2><p><strong>all：判断可迭代对象的每个元素是否都为True值</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>all([<span class="number">1</span>,<span class="number">2</span>]) <span class="comment">#列表中每个元素逻辑值均为True，返回True</span></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>all([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]) <span class="comment">#列表中0的逻辑值为False，返回False</span></span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>all(()) <span class="comment">#空元组</span></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>all(&#123;&#125;) <span class="comment">#空字典</span></span><br><span class="line"><span class="keyword">True</span></span><br></pre></td></tr></table></figure><p><strong>any：判断可迭代对象的元素是否有为True值的元素</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>any([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]) <span class="comment">#列表元素有一个为True，则返回True</span></span><br><span class="line"><span class="keyword">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>any([<span class="number">0</span>,<span class="number">0</span>]) <span class="comment">#列表元素全部为False，则返回False</span></span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>any([]) <span class="comment">#空列表</span></span><br><span class="line"><span class="keyword">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>any(&#123;&#125;) <span class="comment">#空字典</span></span><br><span class="line"><span class="keyword">False</span></span><br></pre></td></tr></table></figure><p><strong>filter：使用指定方法过滤可迭代对象的元素</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = list(range(<span class="number">1</span>,<span class="number">10</span>)) <span class="comment">#定义序列</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">if_odd</span><span class="params">(x)</span>:</span> <span class="comment">#定义奇数判断函数</span></span><br><span class="line">    <span class="keyword">return</span> x%<span class="number">2</span>==<span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(filter(if_odd,a)) <span class="comment">#筛选序列中的奇数</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>]</span><br></pre></td></tr></table></figure><p><strong>map：使用指定方法去作用传入的每个可迭代对象的元素，生成新的可迭代对象</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span> a = str(map(list,[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'b'</span>,<span class="string">'fd'</span>]))<span class="comment">#每一个可迭代对象进行操作</span></span><br><span class="line"> b = list([<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'b'</span>,<span class="string">'fd'</span>])<span class="comment">#对每个元素进行操作</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a,b</span><br><span class="line">[[<span class="string">'a'</span>], [<span class="string">'b'</span>], [<span class="string">'b'</span>], [<span class="string">'f'</span>, <span class="string">'d'</span>]]</span><br><span class="line">[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'b'</span>, <span class="string">'fd'</span>]</span><br></pre></td></tr></table></figure><p><strong>next：返回可迭代对象中的下一个元素值</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = iter(<span class="string">'abcd'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line"><span class="string">'a'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line"><span class="string">'b'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line"><span class="string">'c'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line"><span class="string">'d'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;pyshell#18&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    next(a)</span><br><span class="line">StopIteration</span><br><span class="line"></span><br><span class="line"><span class="comment">#传入default参数后，如果可迭代对象还有元素没有返回，则依次返回其元素值，如果所有元素已经返回，则返回default指定的默认值而不抛出StopIteration 异常</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a,<span class="string">'e'</span>)</span><br><span class="line"><span class="string">'e'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>next(a,<span class="string">'e'</span>)</span><br><span class="line"><span class="string">'e'</span></span><br></pre></td></tr></table></figure><p><strong>reversed：反转序列生成新的可迭代对象</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = reversed(range(<span class="number">10</span>)) <span class="comment"># 传入range对象</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a <span class="comment"># 类型变成迭代器</span></span><br><span class="line">&lt;range_iterator object at <span class="number">0x035634E8</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(a)</span><br><span class="line">[<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure><p><strong>sorted：对可迭代对象进行排序，返回一个新的列表</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'d'</span>,<span class="string">'c'</span>,<span class="string">'B'</span>,<span class="string">'A'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'d'</span>, <span class="string">'c'</span>, <span class="string">'B'</span>, <span class="string">'A'</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sorted(a) <span class="comment"># 默认按字符ascii码排序</span></span><br><span class="line">[<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sorted(a,key = str.lower) <span class="comment"># 转换成小写后再排序，'a'和'A'值一样，'b'和'B'值一样</span></span><br><span class="line">[<span class="string">'a'</span>, <span class="string">'A'</span>, <span class="string">'b'</span>, <span class="string">'B'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>]</span><br></pre></td></tr></table></figure><p><strong>zip：聚合传入的每个迭代器中相同位置的元素，返回一个新的元组类型迭代器</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>] <span class="comment">#长度3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>] <span class="comment">#长度5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(zip(x,y)) <span class="comment"># 取最小长度3</span></span><br><span class="line">[(<span class="number">1</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">6</span>)]</span><br></pre></td></tr></table></figure><h2 id="对象操作">对象操作</h2><p><strong>dir：返回对象或者当前作用域内的属性列表</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dir(list)<span class="comment">#非常重要的list属性，leetcode写代码可以直接用！</span></span><br><span class="line">[<span class="string">'__add__'</span>, <span class="string">'__class__'</span>, <span class="string">'__contains__'</span>, <span class="string">'__delattr__'</span>, <span class="string">'__delitem__'</span>, <span class="string">'__dir__'</span>, <span class="string">'__doc__'</span>, <span class="string">'__eq__'</span>, <span class="string">'__format__'</span>, <span class="string">'__ge__'</span>, <span class="string">'__getattribute__'</span>, <span class="string">'__getitem__'</span>, <span class="string">'__gt__'</span>, <span class="string">'__hash__'</span>, <span class="string">'__iadd__'</span>, <span class="string">'__imul__'</span>, <span class="string">'__init__'</span>, <span class="string">'__init_subclass__'</span>, <span class="string">'__iter__'</span>, <span class="string">'__le__'</span>, <span class="string">'__len__'</span>, <span class="string">'__lt__'</span>, <span class="string">'__mul__'</span>, <span class="string">'__ne__'</span>, <span class="string">'__new__'</span>, <span class="string">'__reduce__'</span>, <span class="string">'__reduce_ex__'</span>, <span class="string">'__repr__'</span>, <span class="string">'__reversed__'</span>, <span class="string">'__rmul__'</span>, <span class="string">'__setattr__'</span>, <span class="string">'__setitem__'</span>, <span class="string">'__sizeof__'</span>, <span class="string">'__str__'</span>, <span class="string">'__subclasshook__'</span>, <span class="string">'append'</span>, <span class="string">'clear'</span>, <span class="string">'copy'</span>, <span class="string">'count'</span>, <span class="string">'extend'</span>, <span class="string">'index'</span>, <span class="string">'insert'</span>, <span class="string">'pop'</span>, <span class="string">'remove'</span>, <span class="string">'reverse'</span>, <span class="string">'sort'</span>]</span><br></pre></td></tr></table></figure><p><strong>type：返回对象的类型，或者根据传入的参数创建一个新的类型</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; type(1) # 返回对象的类型</span><br><span class="line">&lt;class &apos;int&apos;&gt;</span><br><span class="line"></span><br><span class="line">#使用type函数创建类型D，含有属性InfoD</span><br><span class="line">&gt;&gt;&gt; D = type(&apos;D&apos;,(A,B),dict(InfoD=&apos;some thing defined in D&apos;))</span><br><span class="line">&gt;&gt;&gt; d = D()</span><br><span class="line">&gt;&gt;&gt; d.InfoD</span><br><span class="line"> &apos;some thing defined in D&apos;</span><br></pre></td></tr></table></figure><p><strong>len：返回对象的长度</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(<span class="string">'abcd'</span>) <span class="comment"># 字符串</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(bytes(<span class="string">'abcd'</span>,<span class="string">'utf-8'</span>)) <span class="comment"># 字节数组</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>)) <span class="comment"># 元组</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]) <span class="comment"># 列表</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(range(<span class="number">1</span>,<span class="number">5</span>)) <span class="comment"># range对象</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(&#123;<span class="string">'a'</span>:<span class="number">1</span>,<span class="string">'b'</span>:<span class="number">2</span>,<span class="string">'c'</span>:<span class="number">3</span>,<span class="string">'d'</span>:<span class="number">4</span>&#125;) <span class="comment"># 字典</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(&#123;<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>&#125;) <span class="comment"># 集合</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>len(frozenset(<span class="string">'abcd'</span>)) <span class="comment">#不可变集合</span></span><br></pre></td></tr></table></figure><h2 id="变量操作">变量操作</h2><p><strong>globals：返回当前作用域内的全局变量和其值组成的字典</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>globals()</span><br><span class="line">&#123;<span class="string">'__spec__'</span>: <span class="keyword">None</span>, <span class="string">'__package__'</span>: <span class="keyword">None</span>, <span class="string">'__builtins__'</span>: &lt;module <span class="string">'builtins'</span> (built-<span class="keyword">in</span>)&gt;, <span class="string">'__name__'</span>: <span class="string">'__main__'</span>, <span class="string">'__doc__'</span>: <span class="keyword">None</span>, <span class="string">'__loader__'</span>: &lt;<span class="class"><span class="keyword">class</span> '<span class="title">_frozen_importlib</span>.<span class="title">BuiltinImporter</span>'&gt;&#125;</span></span><br><span class="line">&gt;&gt;&gt; a = 1</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>globals() <span class="comment">#多了一个a</span></span><br><span class="line">&#123;<span class="string">'__spec__'</span>: <span class="keyword">None</span>, <span class="string">'__package__'</span>: <span class="keyword">None</span>, <span class="string">'__builtins__'</span>: &lt;module <span class="string">'builtins'</span> (built-<span class="keyword">in</span>)&gt;, <span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'__name__'</span>: <span class="string">'__main__'</span>, <span class="string">'__doc__'</span>: <span class="keyword">None</span>, <span class="string">'__loader__'</span>: &lt;<span class="class"><span class="keyword">class</span> '<span class="title">_frozen_importlib</span>.<span class="title">BuiltinImporter</span>'&gt;&#125;</span></span><br></pre></td></tr></table></figure><p><strong>global：定义全局变量</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">fg</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">global</span> a</span><br><span class="line">    a=<span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fg()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">1</span></span><br><span class="line">&gt;&gt;&gt;<span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">()</span>:</span></span><br><span class="line">    a=<span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Traceback (most recent call last):</span><br><span class="line"> File <span class="string">"&lt;ipython-input-8-60b725f10c9c&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">a</span><br><span class="line">NameError: name <span class="string">'a'</span> <span class="keyword">is</span> <span class="keyword">not</span> defined</span><br></pre></td></tr></table></figure><p><strong>locals：返回当前作用域内的局部变量和其值组成的字典(在调试函数的时候可以返回local)</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">()</span>:</span></span><br><span class="line">        print(<span class="string">'before define a '</span>)</span><br><span class="line">        print(locals()) <span class="comment">#作用域内无变量</span></span><br><span class="line">        a = <span class="number">1</span></span><br><span class="line">        print(<span class="string">'after define a'</span>)</span><br><span class="line">        print(locals()) <span class="comment">#作用域内有一个a变量，值为1</span></span><br><span class="line">        b=a**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> locals()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f</span><br><span class="line">&lt;function f at <span class="number">0x03D40588</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f()</span><br><span class="line">before define a </span><br><span class="line">&#123;&#125; </span><br><span class="line">after define a</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">1</span>, <span class="string">'b'</span>: <span class="number">1</span>&#125;</span><br></pre></td></tr></table></figure><h2 id="交互操作">交互操作</h2><p><strong>print：向标准输出对象打印输出</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="number">1</span> <span class="number">2</span> <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'v'</span>, <span class="string">'f'</span>, <span class="string">'s'</span>, <span class="string">'a'</span>]</span><br><span class="line">print(a,sep = <span class="string">'+'</span>)</span><br><span class="line">[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'v'</span>, <span class="string">'f'</span>, <span class="string">'s'</span>, <span class="string">'a'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(a,a,sep = <span class="string">'+'</span>,end = <span class="string">'=!'</span>)</span><br><span class="line">[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'v'</span>, <span class="string">'f'</span>, <span class="string">'s'</span>, <span class="string">'a'</span>]+[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'v'</span>, <span class="string">'f'</span>, <span class="string">'s'</span>, <span class="string">'a'</span>]=！</span><br></pre></td></tr></table></figure><p><strong>input：读取用户输入值</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>file = input(<span class="string">'please enter your filename:'</span>)</span><br><span class="line">please input your name:cat.png</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>file</span><br><span class="line"><span class="string">'cat.png'</span></span><br></pre></td></tr></table></figure><h2 id="文件操作">文件操作</h2><p><strong>open：使用指定的模式和编码打开文件，返回文件读写对象</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rb为二进制读,wb为二进制写操作</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = open(<span class="string">'test.txt'</span>,<span class="string">'rt'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.read()</span><br><span class="line"><span class="string">'read test'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f.close()</span><br><span class="line"><span class="comment">#读操作:</span></span><br><span class="line">    <span class="comment">#read()将文本文件所有行读到一个字符串中。 </span></span><br><span class="line">    <span class="comment">#readline()是一行一行的读</span></span><br><span class="line">    <span class="comment">#readlines()是将文本文件中所有行读到一个list中，文本文件每一行是list的一个元素。</span></span><br></pre></td></tr></table></figure><blockquote><p>参考：</p><ol type="1"><li><a href="http://blog.csdn.net/oaa608868/article/details/53506188" target="_blank" rel="noopener">Python内置函数详解——总结篇</a></li><li><a href="http://kissg.me/2016/04/09/python-generator-yield/" target="_blank" rel="noopener">Python之生成器详解</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> list </tag>
            
            <tag> yield </tag>
            
            <tag> map </tag>
            
            <tag> zip </tag>
            
            <tag> lambda </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Leetcode 排好序的数组合并求中位数(复杂度限制O(log (m+n)))</title>
      <link href="/2018/07/25/Leetcode%20%E6%8E%92%E5%A5%BD%E5%BA%8F%E7%9A%84%E6%95%B0%E7%BB%84%E5%90%88%E5%B9%B6%E6%B1%82%E4%B8%AD%E4%BD%8D%E6%95%B0(%E5%A4%8D%E6%9D%82%E5%BA%A6%E9%99%90%E5%88%B6O(log%20(m+n)))/"/>
      <url>/2018/07/25/Leetcode%20%E6%8E%92%E5%A5%BD%E5%BA%8F%E7%9A%84%E6%95%B0%E7%BB%84%E5%90%88%E5%B9%B6%E6%B1%82%E4%B8%AD%E4%BD%8D%E6%95%B0(%E5%A4%8D%E6%9D%82%E5%BA%A6%E9%99%90%E5%88%B6O(log%20(m+n)))/</url>
      <content type="html"><![CDATA[<h4 id="leetcode">Leetcode</h4><h5 id="第四题">第四题</h5><pre><code>- There are two sorted arrays nums1 and nums2 of size m and n respectively.</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- Find the median of the two sorted arrays. The overall run time complexity should be O(log (m+n)).</span><br></pre></td></tr></table></figure><a id="more"></a><p><br>Solution:<br>思路：将俩个数组合并成sorted数组，找中位数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">俩个数组排序合并，找中位数</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMedianSortedArrays</span><span class="params">(self, nums1, nums2)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums1: List[int]</span></span><br><span class="line"><span class="string">        :type nums2: List[int]</span></span><br><span class="line"><span class="string">        :rtype: float</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        mergnums=[]</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">print</span> (len(nums1),len(nums2))</span><br><span class="line">        nums1 = list(nums1)</span><br><span class="line">        nums2 = list(nums2)</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            <span class="keyword">if</span> nums1!=[] <span class="keyword">and</span> nums2 !=[]:</span><br><span class="line">                <span class="keyword">if</span> nums1[i]&lt;=nums2[j]:</span><br><span class="line">                    mergnums.append(nums1[i])</span><br><span class="line">                    <span class="keyword">del</span> nums1[i]</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    mergnums.append(nums2[j])</span><br><span class="line">                    <span class="keyword">del</span> nums2[j]</span><br><span class="line">                    <span class="keyword">print</span> (j)            </span><br><span class="line">            <span class="keyword">elif</span> nums1 !=[] <span class="keyword">and</span> nums2 ==[]:</span><br><span class="line">                mergnums.append(nums1[i])</span><br><span class="line">                <span class="keyword">del</span> nums1[i]</span><br><span class="line">            <span class="keyword">elif</span> nums1 ==[] <span class="keyword">and</span> nums2 !=[]:</span><br><span class="line">                mergnums.append(nums2[j])</span><br><span class="line">                <span class="keyword">del</span> nums2[j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span>  </span><br><span class="line">        <span class="keyword">if</span> (len(mergnums))%<span class="number">2</span> ==<span class="number">0</span>:</span><br><span class="line">            median = mergnums[int((len(mergnums)<span class="number">-2</span>)/<span class="number">2</span>)] + mergnums[int(len(mergnums)/<span class="number">2</span>)]</span><br><span class="line">            median = median/<span class="number">2.0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            median = mergnums[int(len(mergnums)/<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">return</span> median</span><br></pre></td></tr></table></figure><p>​<br>​</p>]]></content>
      
      <categories>
          
          <category> -Leetcode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -合并数组求中位数 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>前言</title>
      <link href="/2018/07/23/%E5%89%8D%E8%A8%80/"/>
      <url>/2018/07/23/%E5%89%8D%E8%A8%80/</url>
      <content type="html"><![CDATA[<p>  希望自己能有这个博客来鼓励自己养成总结归纳的好习惯！工具性代码还得review自己写的代码！</p><p>  向大佬们学习！</p><a id="more"></a><ul><li>博客从找工作的角度展开，从算法，算法编程练习俩个角度开始写博客。<ol type="1"><li><p>算法：</p><ol type="1"><li>机器学习基础：<ul><li>[ ] KNN</li><li>[ ] Kmeans</li><li>[ ] SVM</li><li>[ ] 朴素贝叶斯</li><li>[ ] LR</li><li>[ ] RF</li><li>[x] GDBT</li><li>[x] Adaboost</li><li>[ ] LightGBM</li><li>[ ] Xgboost</li></ul></li><li>深度学习基础：<ul><li>[x] CNN 原理与架构发展</li><li>[ ] 反向传播推导</li><li>[ ] 正则化方法</li><li>[ ] 损失函数</li><li>[ ] CNN复杂度计算与模型压缩</li><li>[ ] SSD</li><li>[ ] Retinanet</li><li>[ ] YOLO系列</li><li>[ ] RCNN系列</li></ul></li><li>深度学习优化方法：<ul><li>[ ] 梯度下降优化算法</li></ul></li><li>项目方法总结：<ul><li>[ ] CTR预估算法</li><li>[ ] Multi-label imbalance Classification</li><li>[ ] Zero-shot learing</li></ul></li></ol></li><li><p>编程相关</p></li></ol></li><li><p>以后工作作为技术积累的记录</p></li><li><p>快乐Farm每一天！</p></li></ul>]]></content>
      
      <categories>
          
          <category> 感悟 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 题记 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
